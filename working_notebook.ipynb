{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FISP Twitter Projects Notebook\n",
    "\n",
    "This notebook contains the latest code for pulling tweets and cleaning, manipilating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "#sys.path.append(\"/usr/local/lib/python2.7/site-packages\")\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "# import dropbox #https://www.dropbox.com/developers-v1/core/docs/python\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from unidecode import unidecode\n",
    "import xlsxwriter\n",
    "\n",
    "#Twitter and Dropbox API credentials\n",
    "import api_cred as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup debug logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify print precison for easier debugging\n",
    "np.set_printoptions(precision=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_twitter():\n",
    "  auth = tweepy.OAuthHandler(ac.consumer_key, ac.consumer_secret)\n",
    "  auth.set_access_token(ac.access_key, ac.access_secret)\n",
    "  api = tweepy.API(auth)\n",
    "  return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_tweets(tweet_name, since_id):\n",
    "  api = authenticate_twitter()\n",
    "  tweets = []\n",
    "  new_tweets = api.user_timeline(screen_name = tweet_name, since_id = since_id, count = 200)\n",
    "  tweets.extend(new_tweets)\n",
    "  if len(tweets) > 0:\n",
    "    max_id = tweets[-1].id - 1\n",
    "  while (len(new_tweets) > 0):\n",
    "    new_tweets = api.user_timeline(screen_name = tweet_name, since_id = since_id, count = 200, max_id = max_id)\n",
    "    tweets.extend(new_tweets)\n",
    "    max_id = tweets[-1].id - 1\n",
    "  \n",
    "  tweets = [[tweet.id_str, tweet.created_at, tweet.text, \"\", \"\", \"\",tweet.retweet_count, tweet.favorite_count] for tweet in tweets]\n",
    "  logger.info(\"Downloading %d tweets from %s\" % (len(tweets), tweet_name))\n",
    "  return tweets[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists(df):\n",
    "  # put twitter handles, last acquired tweet ID, tweet count and store them in respective lists\n",
    "  names = filter(lambda x: x > 0, df.iloc[:, 1])\n",
    "  max_ids = df.iloc[:, 2]\n",
    "  counts = df.iloc[:, 3]\n",
    "  \n",
    "  # save the number of entries\n",
    "  indices = range(1,len(names)+1)\n",
    "  \n",
    "  lists = zip(names, max_ids, counts, indices)\n",
    "  del lists[0] # the first one is column title\n",
    "  return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sheets(path):\n",
    "  sheet_book = load_workbook(path)\n",
    "  sheet_writer = pd.ExcelWriter(path, engine='openpyxl')\n",
    "  sheet_writer.book = sheet_book\n",
    "  sheet_writer.sheets = dict((ws.title, ws) for ws in sheet_book.worksheets)\n",
    "  logger.info(\"Downloaded %s\" % path)\n",
    "  return sheet_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_full_url(short_urls, full_urls):\n",
    "  for i, us in enumerate(short_urls):\n",
    "    full = []\n",
    "    if not us.startswith(\"http\"):\n",
    "      continue\n",
    "    for url in us.split(\" \"):\n",
    "      if not url.startswith(\"http\"):\n",
    "        continue\n",
    "      try:\n",
    "        r = requests.head(url, allow_redirects=True)\n",
    "        full.append(r.url)\n",
    "      except:\n",
    "        logger.info(\"Error occurred for URL - %s\" % url)\n",
    "        continue\n",
    "    if i % 500 == 0:\n",
    "        logger.info(\"Extracting URL %d/%d\" % (i, len(short_urls)))\n",
    "        time.sleep(60)\n",
    "    full_urls[i] = \" \".join(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Sheets ↓\n",
    "\n",
    "The functions below write data to the currently local sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Tweets and save them to respective excel file\n",
    "\n",
    "*twitter_list.xlsx* contains the list of candidates for each tweets excel file along with the metadata.\n",
    "\n",
    "*cand_tweets.xlsx* contains the tweets for all announced candidates\n",
    "\n",
    "*spec_tweets.xlsx* contains the tweets for all the speculated candidates\n",
    "\n",
    "*rep_tweets.xlsx* contains the tweets for all current CA represenatives of interest for the CA 2018 Elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# collect_data(tweet_sheet, twitter_list, twitter_sheet)\n",
    "# This function pulls new latest tweets and appends them to the correct excel file\n",
    "# params: tweet_sheet - the path to the excel file to save the new tweets \n",
    "#         twitter_list - path to file that contains the twitter handles, last tweet pulled id, tweet counts, and \n",
    "#                        last pull date\n",
    "#         twitter_sheet - the correct sheet of accounts corresponding to the tweet sheet passed in / accepts list of \n",
    "#                         sheets\n",
    "# returns: n/a\n",
    "def collect_data(tweet_sheet, twitter_list, twitter_list_sheet):\n",
    "  # start timer\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  \n",
    "  # process the paths so they are passable to load_sheets\n",
    "  tweets_path = os.path.expanduser(tweet_sheet)\n",
    "  twitter_list_path = os.path.expanduser(twitter_list)\n",
    "  \n",
    "  # list_df['Last_Pulled'] = pd.to_datetime(list_df['Last_Pulled'], errors='coerce') # used to fix datetime formatting\n",
    "  # if a single sheet is passed in add it to a single item list\n",
    "  if (type(twitter_list_sheet) == str):\n",
    "    twitter_list_sheet = [twitter_list_sheet]\n",
    "  \n",
    "  # properly load spreadsheet to append new data\n",
    "  tweet_writer = load_sheets(tweets_path)\n",
    "  \n",
    "  for sheet in twitter_list_sheet:\n",
    "  \n",
    "    # load and prepare list of twitter accounts    \n",
    "    list_writer = load_sheets(twitter_list_path)\n",
    "    list_df = pd.read_excel(twitter_list_path, sheetname=sheet)\n",
    "    \n",
    "    # loop through the list of Cand/PACs and updates each tweet sheet appropriately\n",
    "    for index, row in list_df.iterrows():       \n",
    "      name, since_id, count = row[1], row[2],row[3]\n",
    "      \n",
    "      # check if rep has a twitter handle \n",
    "      if (type(name) is not unicode):\n",
    "        continue\n",
    "      \n",
    "      new_tweets = get_new_tweets(name, since_id)\n",
    "      \n",
    "      # if there are no new tweets continue to the next account\n",
    "      if (len(new_tweets) > 0):\n",
    "        # turn the new tweets into a dataframe and write them to the corresponding excel sheet\n",
    "        df = pd.DataFrame(new_tweets)\n",
    "        \n",
    "        df.to_excel(tweet_writer, sheet_name=name, startrow=count+1, header=False, index=False, float_format='string')\n",
    "        \n",
    "        # update since_id, count, and last_pull date in tweet list\n",
    "        list_df.iat[index,2] = new_tweets[len(new_tweets)-1][0] # since_id\n",
    "        list_df.iat[index,3] = count + len(new_tweets) # last_pull\n",
    "        list_df.iat[index,4] = pd.to_datetime(time.strftime(\"%m/%d/%Y %H:%M:%S\"), errors='coerce') # last_pull date\n",
    "        \n",
    "        logger.info(\"Updated new tweets on spreadsheet for %s\" % name)\n",
    "        time.sleep(20)\n",
    "    \n",
    "    # write the updated list and save the changes to the excel sheets\n",
    "    list_df.Last_ID = list_df.Last_ID.astype(str)\n",
    "    list_df.to_excel(list_writer, sheet_name=sheet, index=False) #, float_format='string')\n",
    "  \n",
    "  \n",
    "  list_writer.save()\n",
    "  tweet_writer.save()\n",
    "  \n",
    "  logger.info(\"Done appending new tweets for %s\", twitter_sheet)\n",
    "  # stop timer and print time elapsed for the current data pull\n",
    "  end = time.time()\n",
    "  logger.info(\"Time Elapsed: %d\", float((end-start))/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Updates like and retweet totals\n",
    "def collect_addition_data(tweet_sheet, tweet_list, sheetname):\n",
    "  # start the timer\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  \n",
    "  # process the paths so they are passable to load_sheets\n",
    "  tweet_sheet = os.path.expanduser(tweet_sheet)\n",
    "  tweet_list = os.path.expanduser(tweet_list)\n",
    "  \n",
    "  # load and prepare list of twitter accounts\n",
    "  list_writer = load_sheets(tweet_list)\n",
    "  list_df = pd.read_excel(tweet_list, sheet_name=sheetname)\n",
    "  list_df = list_df.dropna(thresh=4)\n",
    "  # properly load spreadsheet to append new data\n",
    "  tweet_writer = load_sheets(tweet_sheet)\n",
    "  logger.info(\"Downloaded tweets list\")\n",
    "  \n",
    "  # loop through the list of Cand/PACs and updates each tweet sheet appropriately\n",
    "  for row in list_df.itertuples():  \n",
    "    name, since_id, count = row[2], row[3],row[4]\n",
    "    \n",
    "    # check if rep has a twitter handle \n",
    "    if (type(name) is not unicode):\n",
    "      continue\n",
    "    \n",
    "    # read cand tweet sheet\n",
    "    tweets_df = pd.read_excel(tweet_sheet, sheetname=name)\n",
    "    logger.info(\"Retrived data from spreadsheet for %s\" % name)\n",
    "    \n",
    "    # retreive updated tweets\n",
    "    tweets = get_new_tweets(name, 1)\n",
    "    updates_df = pd.DataFrame(tweets)\n",
    "    \n",
    "    if (updates_df.empty):\n",
    "      continue \n",
    "      \n",
    "    # clean dataframe to only include id, retweets, and favorites\n",
    "    updates_df = updates_df[[0, 6, 7]]\n",
    "    updates_df.columns = ['id', 'retweets', 'favorites']\n",
    "    \n",
    "    # call helper fuction to match updated metadata with correct tweets\n",
    "    tweets_df = update_metadata(tweets_df, updates_df, name)\n",
    "    \n",
    "    if (name == 'antonio4ca'):\n",
    "      continue\n",
    "      \n",
    "    # write the updated data to the twitter profile's sheet to be saved\n",
    "    tweets_df.to_excel(tweet_writer, sheet_name=name, index=False, startcol=1)\n",
    "    logger.info(\"Updated data on spreadsheet for %s\" % name)\n",
    "    # 100 second pause between data pulls to avoid token exceptions\n",
    "    time.sleep(20)\n",
    "  \n",
    "  tweet_writer.save()\n",
    "  \n",
    "  logger.info(\"Done collecting additional data\")\n",
    "  # stop timer and print time elapsed for the current data pull\n",
    "  end = time.time()\n",
    "  logger.info(\"Time Elapsed: %d\", float((end-start))/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the up to date metadata and matches it to their respective tweet using a tweet's unique id\n",
    "def update_metadata(tweets_df, updates_df, cand_name): \n",
    "  # convert tweet id to the same type as the updates sheet\n",
    "  tweets_df['id'] = tweets_df['id'].astype(str)\n",
    "  tweets_df.set_index('id', inplace=True)\n",
    "  \n",
    "  ## loop through the updates metadata and updates the tweet sheet\n",
    "  for row in updates_df.itertuples():\n",
    "    tweets_df.at[row[1], 'retweets'] = row[2]\n",
    "    tweets_df.at[row[1], 'favorites'] = row[3]\n",
    "\n",
    "  # drop null rows that could not match with a tweet\n",
    "  tweets_df.dropna(subset=['created_at'], inplace=True)\n",
    "  \n",
    "  return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_full_url(tweets_df, updates_df, cand_name):\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  # dp_client = authenticate_dropbox()\n",
    "  \n",
    "  # load and prepare list of twitter accounts\n",
    "  list_writer = load_sheets(tweet_list)\n",
    "  list_df = pd.read_excel(tweet_list, sheetname=sheetname)\n",
    "  list_df = list_df.dropna(thresh=4)\n",
    "  # properly load spreadsheet to append new data\n",
    "  tweet_writer = load_sheets(tweet_sheet)\n",
    "  logger.info(\"Downloaded tweets list\")\n",
    "    \n",
    "  logger.info(\"Successfully download the list...\")\n",
    "  for e, entry in enumerate(list_df):\n",
    "    if e < 15:\n",
    "      continue\n",
    "\n",
    "    name, since_id, count, index = entry[0], entry[1],entry[2], entry[3]\n",
    "\n",
    "    short_urls = worksheet.col_values(6)\n",
    "    logger.info(\"Downloaded %s URL\", name)\n",
    "    url_datas = ['' for i in xrange(len(short_urls))]\n",
    "    url_datas[0] = 'full URL'\n",
    "\n",
    "    get_full_url(short_urls, url_datas) # transfer short url to full urls and store in url_datas\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    while count < len(short_urls):\n",
    "      amount = min(100, len(short_urls) - count)\n",
    "      cells = worksheet.range('I'+str(count)+':'+'I'+str(count+amount-1))\n",
    "      assert(len(cells) == amount)\n",
    "      for i in range(amount):\n",
    "        cells[i].value = url_datas[count-1]\n",
    "        count += 1\n",
    "      worksheet.update_cells(cells)\n",
    "      logger.info(\"Update cells %d/%d for %s\" %(count, len(short_urls), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_sheets(new_tweet_sheet, new_tweet_list, list_sheet_names):\n",
    "  # start the timer\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  \n",
    "  # will contain name of every accnt \n",
    "  sheet_list = []\n",
    "  \n",
    "  # process the paths so they are passable to load_sheets\n",
    "  new_tweet_sheet = os.path.expanduser(new_tweet_sheet)\n",
    "  new_tweet_list = os.path.expanduser(new_tweet_list)\n",
    "\n",
    "  # check if file already exists\n",
    "  if (os.path.exists(new_tweet_sheet)):\n",
    "    # properly load spreadsheet to append new data\n",
    "    tweet_writer = load_sheets(new_tweet_sheet)\n",
    "    # get a list of the current sheets to ensure no duplicates\n",
    "    sheet_list = tweet_writer.sheets\n",
    "    sheet_list = sheet_list.keys()\n",
    "  else:\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    tweet_writer = pd.ExcelWriter(new_tweet_sheet)\n",
    "  \n",
    "  # load and prepare list of twitter accounts\n",
    "  list_writer = load_sheets(new_tweet_list)\n",
    "    \n",
    "  for sheetname in list_sheet_names:\n",
    "    list_df = pd.read_excel(new_tweet_list, sheetname=sheetname)\n",
    "    list_df = list_df.dropna(axis=0, subset=['Twitter'])\n",
    "    \n",
    "    for row in list_df.itertuples():\n",
    "      name, since_id, count = row[2], row[3],row[4]\n",
    "      if(name not in sheet_list):\n",
    "        sheet_list.append(name)\n",
    "        \n",
    "        # Create a Pandas dataframe from some data.\n",
    "        col_headers = {'id': [np.nan], 'created_at': [np.nan], 'text': [np.nan], 'hashtag#': [np.nan], 'at@': [np.nan],\n",
    "                      'link': [np.nan], 'retweets': [np.nan], 'favorites': [np.nan], 'fullURL': [np.nan]}\n",
    "        tweets_df = pd.DataFrame(col_headers)\n",
    "        tweets_df = tweets_df[['id', 'created_at', 'text', 'hashtag#', 'at@', 'link', 'retweets', 'favorites', 'fullURL']]\n",
    "        \n",
    "        # write the updated data to the twitter profile's sheet to be saved\n",
    "        tweets_df.to_excel(tweet_writer, sheet_name=name, index=False, startcol=0)\n",
    "  \n",
    "  tweet_writer.save()\n",
    "  logger.info(\"Done creating excel doc\")\n",
    "  # stop timer and print time elapsed for the current data pull\n",
    "  end = time.time()\n",
    "  logger.info(\"Time Elapsed: %d\", float((end-start))/60)\n",
    "  return sheet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = create_new_sheets(state_data_dir + state_tweets,  state_data_dir + twitter_list, state_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# convert_xlsx_csv (tweet_sheet, sheetname, tweet_list)\n",
    "# This function takes the excel workbook of tweets and converts it all into a single csv of tweets\n",
    "# params: tweet_sheet - the path to the excel file with the tweets\n",
    "#         tweet_list - path to file that contains the twitter handles, last tweet pulled id, tweet counts, and \n",
    "#                        last pull date\n",
    "#         sheetname - sheet within in tweet_list\n",
    "# returns: n/a\n",
    "def convert_xlsx_csv (tweet_sheet, sheetname, tweet_list):\n",
    "  # start timer\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  \n",
    "  # process the paths so they are passable to load_sheets\n",
    "  tweet_sheet = os.path.expanduser(tweet_sheet)\n",
    "  tweet_list = os.path.expanduser(tweet_list)  \n",
    "    \n",
    "  # load and prepare list of twitter accounts    \n",
    "  list_writer = load_sheets(tweet_list)\n",
    "  list_df = pd.read_excel(tweet_list, sheetname=sheetname)\n",
    "  #merged_corpus = pd.DataFrame(columns=['id', 'created_at', 'text', 'hashtag#', 'at@', 'link', 'retweets', 'favorites', 'full URL'])\n",
    "  merged_df = pd.DataFrame()\n",
    "\n",
    "  initial_loop = True\n",
    "  \n",
    "  # loop through the list of Cand/PACs and updates each tweet sheet appropriately\n",
    "  for index, row in list_df.iterrows():\n",
    "    name = row[0]\n",
    "    \n",
    "    if (initial_loop):\n",
    "      merged_df = pd.read_excel(tweet_sheet, sheetname=name)\n",
    "      merged_df['Name'] = name\n",
    "      num_tweets = len(merged_df.index)\n",
    "      print num_tweets\n",
    "\n",
    "      logger.info(\"Retrived data from spreadsheet for %s\" % name)\n",
    "      initial_loop = False\n",
    "    \n",
    "    else:\n",
    "      # read current cand tweet sheet\n",
    "      curr_df = pd.read_excel(tweet_sheet, sheetname=name)\n",
    "      curr_df['Name'] = name\n",
    "      num_tweets = len(curr_df.index)\n",
    "      if (num_tweets == 0):\n",
    "        continue\n",
    "      \n",
    "      logger.info(\"Retrived data from spreadsheet for %s\" % name)\n",
    "      \n",
    "      merged_df = merged_df.append(curr_df)\n",
    "  \n",
    "  print merged_df.shape\n",
    "  # write the updated list and save the changes to the excel sheets\n",
    "  #merged_df.to_csv('merged_corpus.csv', encoding='utf-8')\n",
    "  \n",
    "  logger.info(\"done\")\n",
    "  return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I honestly don't remember what I used this for \n",
    "def list_to_number_string(value):\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        print str(value) + 'here'\n",
    "        return str(value)[1:-1]\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# sample_df['text'] = sample_df['text'].apply(list_to_number_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# func that will pull a number of tweets and create a coding sheet with columns for rating\n",
    "# sentitment, partisanship, policy, fact, and opinion\n",
    "# params: coding_workbook - the path to the excel file containing the tweets\n",
    "#         sheetname - sheet containing all of the tweets\n",
    "#         sample_size - the size of the random sample to be taken from the full corpus of tweets\n",
    "#         sample_name - the name of the sample used as the sheet name in the coding file\n",
    "# returns: returns the samples dataframe\n",
    "def coding_sampling(coding_workbook, sheetname, sample_size, sample_name):\n",
    "  logger.info(\"Start...\")\n",
    "  start = time.time()\n",
    "  \n",
    "  # properly load spreadsheet to append new data\n",
    "  coding_workbook = os.path.expanduser(coding_workbook)\n",
    "  sample_writer = load_sheets(coding_workbook)\n",
    "  full_df = pd.read_excel(coding_workbook, sheetname)\n",
    "  logger.info(\"Full data loaded\")\n",
    "  \n",
    "  col_headers = {'id': [str],'text': [np.nan], 'sentiment': [np.nan], 'political': [np.nan], 'ideology': [np.nan],\n",
    "                 'macroeconomics': [np.nan], 'immigration':[np.nan], 'national_security': [np.nan], 'ideology': [np.nan],\n",
    "                 'crime_law_enforcement': [np.nan], 'civil_rights': [np.nan], 'environment': [np.nan],\n",
    "                 'education': [np.nan], 'healthcare': [np.nan], 'governance': [np.nan], 'no_policy_content': [np.nan],\n",
    "                 'asks_for_donation': [np.nan], 'ask_to_watch_read_share_follow_something': [np.nan],\n",
    "                 'factual_claim': [np.nan], 'opinion': [np.nan]}\n",
    "  sample_df = pd.DataFrame(col_headers)\n",
    "  \n",
    "  # keep only id and text \n",
    "  full_df = full_df[['id', 'text']]\n",
    "  \n",
    "  if( (len(sample_writer.sheets) > 1)):\n",
    "    # get a list of the names of the sampled sheets, skip the first sheet since it contains all the data\n",
    "    sampled_sheets = sample_writer.sheets\n",
    "    sampled_sheets = (list(sampled_sheets.keys()))[1:]\n",
    "    print sampled_sheets\n",
    "    full_df_col = list(full_df)\n",
    "    print len(full_df.index)\n",
    "    # loop thru the sheets and remove the tweets by id \n",
    "    for sheet in sampled_sheets:\n",
    "      sampled_df = pd.read_excel(coding_workbook, sheet)\n",
    "      cleaned_df = pd.merge(full_df, sampled_df, how='outer', on='id', indicator=True)\n",
    "      cleaned_df = cleaned_df[cleaned_df['_merge'] == 'left_only']\n",
    "      cleaned_df = cleaned_df.drop(['_merge', 'text_y'], axis=1)\n",
    "      cleaned_df = cleaned_df.rename(index=str, columns={'text_x': 'text'})\n",
    "      full_df = cleaned_df\n",
    "      full_df = full_df[full_df_col]\n",
    "    print len(full_df.index)\n",
    "  \n",
    "  # sample the tweets\n",
    "  sample_tweets = full_df.sample(sample_size)\n",
    "  logger.info(\"Sample made\")\n",
    "  \n",
    "  # concat the sampled tweets with the coding measurments\n",
    "  sample_df = pd.concat([sample_tweets, sample_df], sort=True)\n",
    "  # reaarange the columns\n",
    "  sample_df = sample_df[['id', 'text', 'sentiment', 'political', 'ideology', 'macroeconomics', 'immigration',\n",
    "                         'national_security', 'crime_law_enforcement', 'civil_rights', 'environment', 'education',\n",
    "                         'healthcare', 'governance', 'no_policy_content', 'asks_for_donation',\n",
    "                         'ask_to_watch_read_share_follow_something', 'factual_claim', 'opinion']]\n",
    "  sample_df.drop(sample_df.tail(1).index,inplace=True) # drop last n rows\n",
    "  logger.info(\"Sample processed and concated\")\n",
    "  \n",
    "  # ensure id field is string to avoid excel float/sci rounding \n",
    "  #sample_df.id = sample_df.id.astype(str)\n",
    "  #sample_df.to_excel(sample_writer, sample_name, index=False, float_format='string')\n",
    "  #sample_writer.save()\n",
    "  \n",
    "  # testing the exlude portion\n",
    "  if( (len(sample_writer.sheets) > 1)):\n",
    "    # get a list of the names of the sampled sheets, skip the first sheet since it contains all the data\n",
    "    sampled_sheets = sample_writer.sheets\n",
    "    sampled_sheets = (sampled_sheets.keys())[1:0]\n",
    "    full_df_col = list(full_df_col)\n",
    "    failed_excludes = 0\n",
    "    \n",
    "    # loop thru the sheets and remove the tweets by id \n",
    "    for sheet in sampled_sheets:\n",
    "      sampled_df = pd.read_excel(coding_workbook, sheet)\n",
    "      cleaned_df = pd.merge(full_df, how='inner', on='id')\n",
    "      failed_excludes = failed_excludes + len(cleaned_df.index)\n",
    "    logger.info(\"The number of failed excludes: %d\", failed_excludes)\n",
    "      \n",
    "  \n",
    "  logger.info(\"done\")\n",
    "  return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Start...\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/coding_file.xlsx\n",
      "INFO:__main__:Full data loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'batch2', u'batch1']\n",
      "775094\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sample made\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Sample processed and concated\n",
      "INFO:__main__:The number of failed excludes: 0\n",
      "INFO:__main__:done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>political</th>\n",
       "      <th>ideology</th>\n",
       "      <th>macroeconomics</th>\n",
       "      <th>immigration</th>\n",
       "      <th>national_security</th>\n",
       "      <th>crime_law_enforcement</th>\n",
       "      <th>civil_rights</th>\n",
       "      <th>environment</th>\n",
       "      <th>education</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>governance</th>\n",
       "      <th>no_policy_content</th>\n",
       "      <th>asks_for_donation</th>\n",
       "      <th>ask_to_watch_read_share_follow_something</th>\n",
       "      <th>factual_claim</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482207</th>\n",
       "      <td>901510579764031489</td>\n",
       "      <td>An awesome group that's ready for 2018! Glad t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269841</th>\n",
       "      <td>943860774413438976</td>\n",
       "      <td>Only 37,689 more residents to go! #comebacksta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422324</th>\n",
       "      <td>400702466246705152</td>\n",
       "      <td>I posted 40 photos on Facebook in the album \"N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284404</th>\n",
       "      <td>821211419857354752</td>\n",
       "      <td>RT @mike_pence: Honored 2 take oath from Justi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625375</th>\n",
       "      <td>589804148205326336</td>\n",
       "      <td>RT @OCPDB5: Thanks @billclinton for your wonde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619837</th>\n",
       "      <td>867075651387437056</td>\n",
       "      <td>My thoughts on a potential Oklahoma budget pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621584</th>\n",
       "      <td>9164466447</td>\n",
       "      <td>It is time for our National Defense to mean ju...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347820</th>\n",
       "      <td>963208589325324288</td>\n",
       "      <td>@lyman_brian Old Abe was a political genius. J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771109</th>\n",
       "      <td>522084923931656193</td>\n",
       "      <td>Video from today's #PASenate Urban Affairs &amp;am...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658144</th>\n",
       "      <td>912777191951396864</td>\n",
       "      <td>RT @PPact: If the people impacted aren't at th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387034</th>\n",
       "      <td>956199411889172482</td>\n",
       "      <td>Always happy to meet with my constituents http...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311770</th>\n",
       "      <td>9748617962</td>\n",
       "      <td>Yes I am above Hana.  Trying to tweet as thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241521</th>\n",
       "      <td>807549234635558913</td>\n",
       "      <td>As if the shenanigans of Jill Stein and Mark B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722811</th>\n",
       "      <td>925006280250490881</td>\n",
       "      <td>Watch live at 11 a.m. Senate ERE Committee hea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362110</th>\n",
       "      <td>579095443532988416</td>\n",
       "      <td>Historic Sites Director who removed Wallace po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175227</th>\n",
       "      <td>872117698775445504</td>\n",
       "      <td>Attending college or trade school is a reliabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104774</th>\n",
       "      <td>684555161231036416</td>\n",
       "      <td>Families Caring for Adults with Intellectual D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343519</th>\n",
       "      <td>205527740978438145</td>\n",
       "      <td>The Senate is now in its 6th day of the specia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471775</th>\n",
       "      <td>938520306133622784</td>\n",
       "      <td>RT @azstateforestry: Today we received orders ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768610</th>\n",
       "      <td>734786092440883200</td>\n",
       "      <td>Tks McGuiffey Middle School for inviting me to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266641</th>\n",
       "      <td>819371858814496768</td>\n",
       "      <td>RT @MBurden_DN: .@GM @GMdudeinNA says the igni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312579</th>\n",
       "      <td>330884485447053313</td>\n",
       "      <td>@janesherd http://t.co/ea7TC1TgcX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408565</th>\n",
       "      <td>809918930672373760</td>\n",
       "      <td>It's been a busy week in and outside of the of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126400</th>\n",
       "      <td>938145278363873280</td>\n",
       "      <td>Gov. Rauner Seeking Re-election: ‘I Am Not in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468202</th>\n",
       "      <td>956584085102542848</td>\n",
       "      <td>RT @azcentral: VIDEO: News media across the co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212128</th>\n",
       "      <td>969610471925043200</td>\n",
       "      <td>This Week in the State Senate | February 26th ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38542</th>\n",
       "      <td>314260701709492224</td>\n",
       "      <td>RT @usairforce: Lt.Col. Nicole Malachowski is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24511</th>\n",
       "      <td>701920919044796416</td>\n",
       "      <td>RT @TimValderrama: @dredhernandez says the det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220519</th>\n",
       "      <td>827663698886025216</td>\n",
       "      <td>RT @GDOTATL: #FalconsFriday GDOT employees fro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>846434667808997376</td>\n",
       "      <td>Data shows “sanctuary” counties have lower cri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213750</th>\n",
       "      <td>67297133975437312</td>\n",
       "      <td>Great weekend.  Attended the CDA Derby Party a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431907</th>\n",
       "      <td>236126458001641472</td>\n",
       "      <td>Be a yardstick of quality. Some people aren't ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274075</th>\n",
       "      <td>427159895050166272</td>\n",
       "      <td>#MISOS Ruth Johnson is honored to serve as the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693537</th>\n",
       "      <td>534361361216966656</td>\n",
       "      <td>RT @SDoLancaster: Enjoying a good book on a ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148007</th>\n",
       "      <td>866786198173483009</td>\n",
       "      <td>RT @ILSenDems: Illinois has waited too long, t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284998</th>\n",
       "      <td>851296730297532416</td>\n",
       "      <td>RT @NBCNews: Florida sheriff, flanked by maske...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761417</th>\n",
       "      <td>666702427639431168</td>\n",
       "      <td>Celebrating father's today with Father's Colla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587313</th>\n",
       "      <td>797870768616898560</td>\n",
       "      <td>@jackquig Submitting new slate of bill drafts ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226430</th>\n",
       "      <td>953357512455139328</td>\n",
       "      <td>Congratulations to my friend, supporter, Haral...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62602</th>\n",
       "      <td>276049615244124160</td>\n",
       "      <td>RT @AssemblyGOP: @EricLinder worked in real es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464203</th>\n",
       "      <td>785670655824060416</td>\n",
       "      <td>RT @MadamChairAT: Jeez... imagine if a DEM sai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609207</th>\n",
       "      <td>589809868233527298</td>\n",
       "      <td>RT @stevejohnsonokc: President Bill Clinton ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440825</th>\n",
       "      <td>948615809449930752</td>\n",
       "      <td>Sonoran Outfitters to Refund Consumers after F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324790</th>\n",
       "      <td>439935037316661248</td>\n",
       "      <td>RT @TheJessie33: #ElectHer speaker @jilltokuda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194923</th>\n",
       "      <td>946786367337648129</td>\n",
       "      <td>RT @CaricMartin: Chart &amp;amp; quote @wsj today ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95488</th>\n",
       "      <td>499432486418808832</td>\n",
       "      <td>@lynnlovegreen Thank you!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708326</th>\n",
       "      <td>974590097109680128</td>\n",
       "      <td>RT @barbs73: Beware of the Trojan Horse! In pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398246</th>\n",
       "      <td>760947371161296896</td>\n",
       "      <td>Alternately, new or unaffiliated voters can re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266230</th>\n",
       "      <td>760818092926652416</td>\n",
       "      <td>RT @Michigandmurray: .@onetoughnerd and @PaulW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765350</th>\n",
       "      <td>869261035974381568</td>\n",
       "      <td>Honored to participate in Pottstown's Memorial...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163516</th>\n",
       "      <td>124146613617831936</td>\n",
       "      <td>Also follow the #chibudget tweet chat http://t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495581</th>\n",
       "      <td>81066508050112512</td>\n",
       "      <td>Enjoyed a wonderful time at the Estero Chamber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504225</th>\n",
       "      <td>941438553304772609</td>\n",
       "      <td>RT @StPetePolls: @JeffreyBrandes The trend con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355541</th>\n",
       "      <td>243036922841296896</td>\n",
       "      <td>@ThePlumLineGS Keep telling yourself that. Peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195066</th>\n",
       "      <td>953308246919524352</td>\n",
       "      <td>RT @CatholicHerald: Churchill’s cardinal: why ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202418</th>\n",
       "      <td>790724098494128128</td>\n",
       "      <td>Silly Sock Day + Picture Day= confused Mom. #T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502902</th>\n",
       "      <td>858418295111905281</td>\n",
       "      <td>https://t.co/HiaBFPdgKN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396237</th>\n",
       "      <td>611266175327076352</td>\n",
       "      <td>Not what Dr. ordered: Higher taxes on hospital...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166731</th>\n",
       "      <td>700049148217794562</td>\n",
       "      <td>After the speech I went over to the Stratton B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638276</th>\n",
       "      <td>901663742924029953</td>\n",
       "      <td>@harleybz49 @FredForman You have the floor.. P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "482207  901510579764031489  An awesome group that's ready for 2018! Glad t...   \n",
       "269841  943860774413438976  Only 37,689 more residents to go! #comebacksta...   \n",
       "422324  400702466246705152  I posted 40 photos on Facebook in the album \"N...   \n",
       "284404  821211419857354752  RT @mike_pence: Honored 2 take oath from Justi...   \n",
       "625375  589804148205326336  RT @OCPDB5: Thanks @billclinton for your wonde...   \n",
       "619837  867075651387437056  My thoughts on a potential Oklahoma budget pro...   \n",
       "621584          9164466447  It is time for our National Defense to mean ju...   \n",
       "347820  963208589325324288  @lyman_brian Old Abe was a political genius. J...   \n",
       "771109  522084923931656193  Video from today's #PASenate Urban Affairs &am...   \n",
       "658144  912777191951396864  RT @PPact: If the people impacted aren't at th...   \n",
       "387034  956199411889172482  Always happy to meet with my constituents http...   \n",
       "311770          9748617962  Yes I am above Hana.  Trying to tweet as thing...   \n",
       "241521  807549234635558913  As if the shenanigans of Jill Stein and Mark B...   \n",
       "722811  925006280250490881  Watch live at 11 a.m. Senate ERE Committee hea...   \n",
       "362110  579095443532988416  Historic Sites Director who removed Wallace po...   \n",
       "175227  872117698775445504  Attending college or trade school is a reliabl...   \n",
       "104774  684555161231036416  Families Caring for Adults with Intellectual D...   \n",
       "343519  205527740978438145  The Senate is now in its 6th day of the specia...   \n",
       "471775  938520306133622784  RT @azstateforestry: Today we received orders ...   \n",
       "768610  734786092440883200  Tks McGuiffey Middle School for inviting me to...   \n",
       "266641  819371858814496768  RT @MBurden_DN: .@GM @GMdudeinNA says the igni...   \n",
       "312579  330884485447053313                  @janesherd http://t.co/ea7TC1TgcX   \n",
       "408565  809918930672373760  It's been a busy week in and outside of the of...   \n",
       "126400  938145278363873280  Gov. Rauner Seeking Re-election: ‘I Am Not in ...   \n",
       "468202  956584085102542848  RT @azcentral: VIDEO: News media across the co...   \n",
       "212128  969610471925043200  This Week in the State Senate | February 26th ...   \n",
       "38542   314260701709492224  RT @usairforce: Lt.Col. Nicole Malachowski is ...   \n",
       "24511   701920919044796416  RT @TimValderrama: @dredhernandez says the det...   \n",
       "220519  827663698886025216  RT @GDOTATL: #FalconsFriday GDOT employees fro...   \n",
       "28508   846434667808997376  Data shows “sanctuary” counties have lower cri...   \n",
       "...                    ...                                                ...   \n",
       "213750   67297133975437312  Great weekend.  Attended the CDA Derby Party a...   \n",
       "431907  236126458001641472  Be a yardstick of quality. Some people aren't ...   \n",
       "274075  427159895050166272  #MISOS Ruth Johnson is honored to serve as the...   \n",
       "693537  534361361216966656  RT @SDoLancaster: Enjoying a good book on a ra...   \n",
       "148007  866786198173483009  RT @ILSenDems: Illinois has waited too long, t...   \n",
       "284998  851296730297532416  RT @NBCNews: Florida sheriff, flanked by maske...   \n",
       "761417  666702427639431168  Celebrating father's today with Father's Colla...   \n",
       "587313  797870768616898560  @jackquig Submitting new slate of bill drafts ...   \n",
       "226430  953357512455139328  Congratulations to my friend, supporter, Haral...   \n",
       "62602   276049615244124160  RT @AssemblyGOP: @EricLinder worked in real es...   \n",
       "464203  785670655824060416  RT @MadamChairAT: Jeez... imagine if a DEM sai...   \n",
       "609207  589809868233527298  RT @stevejohnsonokc: President Bill Clinton ad...   \n",
       "440825  948615809449930752  Sonoran Outfitters to Refund Consumers after F...   \n",
       "324790  439935037316661248  RT @TheJessie33: #ElectHer speaker @jilltokuda...   \n",
       "194923  946786367337648129  RT @CaricMartin: Chart &amp; quote @wsj today ...   \n",
       "95488   499432486418808832                          @lynnlovegreen Thank you!   \n",
       "708326  974590097109680128  RT @barbs73: Beware of the Trojan Horse! In pa...   \n",
       "398246  760947371161296896  Alternately, new or unaffiliated voters can re...   \n",
       "266230  760818092926652416  RT @Michigandmurray: .@onetoughnerd and @PaulW...   \n",
       "765350  869261035974381568  Honored to participate in Pottstown's Memorial...   \n",
       "163516  124146613617831936  Also follow the #chibudget tweet chat http://t...   \n",
       "495581   81066508050112512  Enjoyed a wonderful time at the Estero Chamber...   \n",
       "504225  941438553304772609  RT @StPetePolls: @JeffreyBrandes The trend con...   \n",
       "355541  243036922841296896  @ThePlumLineGS Keep telling yourself that. Peo...   \n",
       "195066  953308246919524352  RT @CatholicHerald: Churchill’s cardinal: why ...   \n",
       "202418  790724098494128128  Silly Sock Day + Picture Day= confused Mom. #T...   \n",
       "502902  858418295111905281                            https://t.co/HiaBFPdgKN   \n",
       "396237  611266175327076352  Not what Dr. ordered: Higher taxes on hospital...   \n",
       "166731  700049148217794562  After the speech I went over to the Stratton B...   \n",
       "638276  901663742924029953  @harleybz49 @FredForman You have the floor.. P...   \n",
       "\n",
       "        sentiment  political  ideology  macroeconomics  immigration  \\\n",
       "482207        NaN        NaN       NaN             NaN          NaN   \n",
       "269841        NaN        NaN       NaN             NaN          NaN   \n",
       "422324        NaN        NaN       NaN             NaN          NaN   \n",
       "284404        NaN        NaN       NaN             NaN          NaN   \n",
       "625375        NaN        NaN       NaN             NaN          NaN   \n",
       "619837        NaN        NaN       NaN             NaN          NaN   \n",
       "621584        NaN        NaN       NaN             NaN          NaN   \n",
       "347820        NaN        NaN       NaN             NaN          NaN   \n",
       "771109        NaN        NaN       NaN             NaN          NaN   \n",
       "658144        NaN        NaN       NaN             NaN          NaN   \n",
       "387034        NaN        NaN       NaN             NaN          NaN   \n",
       "311770        NaN        NaN       NaN             NaN          NaN   \n",
       "241521        NaN        NaN       NaN             NaN          NaN   \n",
       "722811        NaN        NaN       NaN             NaN          NaN   \n",
       "362110        NaN        NaN       NaN             NaN          NaN   \n",
       "175227        NaN        NaN       NaN             NaN          NaN   \n",
       "104774        NaN        NaN       NaN             NaN          NaN   \n",
       "343519        NaN        NaN       NaN             NaN          NaN   \n",
       "471775        NaN        NaN       NaN             NaN          NaN   \n",
       "768610        NaN        NaN       NaN             NaN          NaN   \n",
       "266641        NaN        NaN       NaN             NaN          NaN   \n",
       "312579        NaN        NaN       NaN             NaN          NaN   \n",
       "408565        NaN        NaN       NaN             NaN          NaN   \n",
       "126400        NaN        NaN       NaN             NaN          NaN   \n",
       "468202        NaN        NaN       NaN             NaN          NaN   \n",
       "212128        NaN        NaN       NaN             NaN          NaN   \n",
       "38542         NaN        NaN       NaN             NaN          NaN   \n",
       "24511         NaN        NaN       NaN             NaN          NaN   \n",
       "220519        NaN        NaN       NaN             NaN          NaN   \n",
       "28508         NaN        NaN       NaN             NaN          NaN   \n",
       "...           ...        ...       ...             ...          ...   \n",
       "213750        NaN        NaN       NaN             NaN          NaN   \n",
       "431907        NaN        NaN       NaN             NaN          NaN   \n",
       "274075        NaN        NaN       NaN             NaN          NaN   \n",
       "693537        NaN        NaN       NaN             NaN          NaN   \n",
       "148007        NaN        NaN       NaN             NaN          NaN   \n",
       "284998        NaN        NaN       NaN             NaN          NaN   \n",
       "761417        NaN        NaN       NaN             NaN          NaN   \n",
       "587313        NaN        NaN       NaN             NaN          NaN   \n",
       "226430        NaN        NaN       NaN             NaN          NaN   \n",
       "62602         NaN        NaN       NaN             NaN          NaN   \n",
       "464203        NaN        NaN       NaN             NaN          NaN   \n",
       "609207        NaN        NaN       NaN             NaN          NaN   \n",
       "440825        NaN        NaN       NaN             NaN          NaN   \n",
       "324790        NaN        NaN       NaN             NaN          NaN   \n",
       "194923        NaN        NaN       NaN             NaN          NaN   \n",
       "95488         NaN        NaN       NaN             NaN          NaN   \n",
       "708326        NaN        NaN       NaN             NaN          NaN   \n",
       "398246        NaN        NaN       NaN             NaN          NaN   \n",
       "266230        NaN        NaN       NaN             NaN          NaN   \n",
       "765350        NaN        NaN       NaN             NaN          NaN   \n",
       "163516        NaN        NaN       NaN             NaN          NaN   \n",
       "495581        NaN        NaN       NaN             NaN          NaN   \n",
       "504225        NaN        NaN       NaN             NaN          NaN   \n",
       "355541        NaN        NaN       NaN             NaN          NaN   \n",
       "195066        NaN        NaN       NaN             NaN          NaN   \n",
       "202418        NaN        NaN       NaN             NaN          NaN   \n",
       "502902        NaN        NaN       NaN             NaN          NaN   \n",
       "396237        NaN        NaN       NaN             NaN          NaN   \n",
       "166731        NaN        NaN       NaN             NaN          NaN   \n",
       "638276        NaN        NaN       NaN             NaN          NaN   \n",
       "\n",
       "        national_security  crime_law_enforcement  civil_rights  environment  \\\n",
       "482207                NaN                    NaN           NaN          NaN   \n",
       "269841                NaN                    NaN           NaN          NaN   \n",
       "422324                NaN                    NaN           NaN          NaN   \n",
       "284404                NaN                    NaN           NaN          NaN   \n",
       "625375                NaN                    NaN           NaN          NaN   \n",
       "619837                NaN                    NaN           NaN          NaN   \n",
       "621584                NaN                    NaN           NaN          NaN   \n",
       "347820                NaN                    NaN           NaN          NaN   \n",
       "771109                NaN                    NaN           NaN          NaN   \n",
       "658144                NaN                    NaN           NaN          NaN   \n",
       "387034                NaN                    NaN           NaN          NaN   \n",
       "311770                NaN                    NaN           NaN          NaN   \n",
       "241521                NaN                    NaN           NaN          NaN   \n",
       "722811                NaN                    NaN           NaN          NaN   \n",
       "362110                NaN                    NaN           NaN          NaN   \n",
       "175227                NaN                    NaN           NaN          NaN   \n",
       "104774                NaN                    NaN           NaN          NaN   \n",
       "343519                NaN                    NaN           NaN          NaN   \n",
       "471775                NaN                    NaN           NaN          NaN   \n",
       "768610                NaN                    NaN           NaN          NaN   \n",
       "266641                NaN                    NaN           NaN          NaN   \n",
       "312579                NaN                    NaN           NaN          NaN   \n",
       "408565                NaN                    NaN           NaN          NaN   \n",
       "126400                NaN                    NaN           NaN          NaN   \n",
       "468202                NaN                    NaN           NaN          NaN   \n",
       "212128                NaN                    NaN           NaN          NaN   \n",
       "38542                 NaN                    NaN           NaN          NaN   \n",
       "24511                 NaN                    NaN           NaN          NaN   \n",
       "220519                NaN                    NaN           NaN          NaN   \n",
       "28508                 NaN                    NaN           NaN          NaN   \n",
       "...                   ...                    ...           ...          ...   \n",
       "213750                NaN                    NaN           NaN          NaN   \n",
       "431907                NaN                    NaN           NaN          NaN   \n",
       "274075                NaN                    NaN           NaN          NaN   \n",
       "693537                NaN                    NaN           NaN          NaN   \n",
       "148007                NaN                    NaN           NaN          NaN   \n",
       "284998                NaN                    NaN           NaN          NaN   \n",
       "761417                NaN                    NaN           NaN          NaN   \n",
       "587313                NaN                    NaN           NaN          NaN   \n",
       "226430                NaN                    NaN           NaN          NaN   \n",
       "62602                 NaN                    NaN           NaN          NaN   \n",
       "464203                NaN                    NaN           NaN          NaN   \n",
       "609207                NaN                    NaN           NaN          NaN   \n",
       "440825                NaN                    NaN           NaN          NaN   \n",
       "324790                NaN                    NaN           NaN          NaN   \n",
       "194923                NaN                    NaN           NaN          NaN   \n",
       "95488                 NaN                    NaN           NaN          NaN   \n",
       "708326                NaN                    NaN           NaN          NaN   \n",
       "398246                NaN                    NaN           NaN          NaN   \n",
       "266230                NaN                    NaN           NaN          NaN   \n",
       "765350                NaN                    NaN           NaN          NaN   \n",
       "163516                NaN                    NaN           NaN          NaN   \n",
       "495581                NaN                    NaN           NaN          NaN   \n",
       "504225                NaN                    NaN           NaN          NaN   \n",
       "355541                NaN                    NaN           NaN          NaN   \n",
       "195066                NaN                    NaN           NaN          NaN   \n",
       "202418                NaN                    NaN           NaN          NaN   \n",
       "502902                NaN                    NaN           NaN          NaN   \n",
       "396237                NaN                    NaN           NaN          NaN   \n",
       "166731                NaN                    NaN           NaN          NaN   \n",
       "638276                NaN                    NaN           NaN          NaN   \n",
       "\n",
       "        education  healthcare  governance  no_policy_content  \\\n",
       "482207        NaN         NaN         NaN                NaN   \n",
       "269841        NaN         NaN         NaN                NaN   \n",
       "422324        NaN         NaN         NaN                NaN   \n",
       "284404        NaN         NaN         NaN                NaN   \n",
       "625375        NaN         NaN         NaN                NaN   \n",
       "619837        NaN         NaN         NaN                NaN   \n",
       "621584        NaN         NaN         NaN                NaN   \n",
       "347820        NaN         NaN         NaN                NaN   \n",
       "771109        NaN         NaN         NaN                NaN   \n",
       "658144        NaN         NaN         NaN                NaN   \n",
       "387034        NaN         NaN         NaN                NaN   \n",
       "311770        NaN         NaN         NaN                NaN   \n",
       "241521        NaN         NaN         NaN                NaN   \n",
       "722811        NaN         NaN         NaN                NaN   \n",
       "362110        NaN         NaN         NaN                NaN   \n",
       "175227        NaN         NaN         NaN                NaN   \n",
       "104774        NaN         NaN         NaN                NaN   \n",
       "343519        NaN         NaN         NaN                NaN   \n",
       "471775        NaN         NaN         NaN                NaN   \n",
       "768610        NaN         NaN         NaN                NaN   \n",
       "266641        NaN         NaN         NaN                NaN   \n",
       "312579        NaN         NaN         NaN                NaN   \n",
       "408565        NaN         NaN         NaN                NaN   \n",
       "126400        NaN         NaN         NaN                NaN   \n",
       "468202        NaN         NaN         NaN                NaN   \n",
       "212128        NaN         NaN         NaN                NaN   \n",
       "38542         NaN         NaN         NaN                NaN   \n",
       "24511         NaN         NaN         NaN                NaN   \n",
       "220519        NaN         NaN         NaN                NaN   \n",
       "28508         NaN         NaN         NaN                NaN   \n",
       "...           ...         ...         ...                ...   \n",
       "213750        NaN         NaN         NaN                NaN   \n",
       "431907        NaN         NaN         NaN                NaN   \n",
       "274075        NaN         NaN         NaN                NaN   \n",
       "693537        NaN         NaN         NaN                NaN   \n",
       "148007        NaN         NaN         NaN                NaN   \n",
       "284998        NaN         NaN         NaN                NaN   \n",
       "761417        NaN         NaN         NaN                NaN   \n",
       "587313        NaN         NaN         NaN                NaN   \n",
       "226430        NaN         NaN         NaN                NaN   \n",
       "62602         NaN         NaN         NaN                NaN   \n",
       "464203        NaN         NaN         NaN                NaN   \n",
       "609207        NaN         NaN         NaN                NaN   \n",
       "440825        NaN         NaN         NaN                NaN   \n",
       "324790        NaN         NaN         NaN                NaN   \n",
       "194923        NaN         NaN         NaN                NaN   \n",
       "95488         NaN         NaN         NaN                NaN   \n",
       "708326        NaN         NaN         NaN                NaN   \n",
       "398246        NaN         NaN         NaN                NaN   \n",
       "266230        NaN         NaN         NaN                NaN   \n",
       "765350        NaN         NaN         NaN                NaN   \n",
       "163516        NaN         NaN         NaN                NaN   \n",
       "495581        NaN         NaN         NaN                NaN   \n",
       "504225        NaN         NaN         NaN                NaN   \n",
       "355541        NaN         NaN         NaN                NaN   \n",
       "195066        NaN         NaN         NaN                NaN   \n",
       "202418        NaN         NaN         NaN                NaN   \n",
       "502902        NaN         NaN         NaN                NaN   \n",
       "396237        NaN         NaN         NaN                NaN   \n",
       "166731        NaN         NaN         NaN                NaN   \n",
       "638276        NaN         NaN         NaN                NaN   \n",
       "\n",
       "        asks_for_donation  ask_to_watch_read_share_follow_something  \\\n",
       "482207                NaN                                       NaN   \n",
       "269841                NaN                                       NaN   \n",
       "422324                NaN                                       NaN   \n",
       "284404                NaN                                       NaN   \n",
       "625375                NaN                                       NaN   \n",
       "619837                NaN                                       NaN   \n",
       "621584                NaN                                       NaN   \n",
       "347820                NaN                                       NaN   \n",
       "771109                NaN                                       NaN   \n",
       "658144                NaN                                       NaN   \n",
       "387034                NaN                                       NaN   \n",
       "311770                NaN                                       NaN   \n",
       "241521                NaN                                       NaN   \n",
       "722811                NaN                                       NaN   \n",
       "362110                NaN                                       NaN   \n",
       "175227                NaN                                       NaN   \n",
       "104774                NaN                                       NaN   \n",
       "343519                NaN                                       NaN   \n",
       "471775                NaN                                       NaN   \n",
       "768610                NaN                                       NaN   \n",
       "266641                NaN                                       NaN   \n",
       "312579                NaN                                       NaN   \n",
       "408565                NaN                                       NaN   \n",
       "126400                NaN                                       NaN   \n",
       "468202                NaN                                       NaN   \n",
       "212128                NaN                                       NaN   \n",
       "38542                 NaN                                       NaN   \n",
       "24511                 NaN                                       NaN   \n",
       "220519                NaN                                       NaN   \n",
       "28508                 NaN                                       NaN   \n",
       "...                   ...                                       ...   \n",
       "213750                NaN                                       NaN   \n",
       "431907                NaN                                       NaN   \n",
       "274075                NaN                                       NaN   \n",
       "693537                NaN                                       NaN   \n",
       "148007                NaN                                       NaN   \n",
       "284998                NaN                                       NaN   \n",
       "761417                NaN                                       NaN   \n",
       "587313                NaN                                       NaN   \n",
       "226430                NaN                                       NaN   \n",
       "62602                 NaN                                       NaN   \n",
       "464203                NaN                                       NaN   \n",
       "609207                NaN                                       NaN   \n",
       "440825                NaN                                       NaN   \n",
       "324790                NaN                                       NaN   \n",
       "194923                NaN                                       NaN   \n",
       "95488                 NaN                                       NaN   \n",
       "708326                NaN                                       NaN   \n",
       "398246                NaN                                       NaN   \n",
       "266230                NaN                                       NaN   \n",
       "765350                NaN                                       NaN   \n",
       "163516                NaN                                       NaN   \n",
       "495581                NaN                                       NaN   \n",
       "504225                NaN                                       NaN   \n",
       "355541                NaN                                       NaN   \n",
       "195066                NaN                                       NaN   \n",
       "202418                NaN                                       NaN   \n",
       "502902                NaN                                       NaN   \n",
       "396237                NaN                                       NaN   \n",
       "166731                NaN                                       NaN   \n",
       "638276                NaN                                       NaN   \n",
       "\n",
       "        factual_claim  opinion  \n",
       "482207            NaN      NaN  \n",
       "269841            NaN      NaN  \n",
       "422324            NaN      NaN  \n",
       "284404            NaN      NaN  \n",
       "625375            NaN      NaN  \n",
       "619837            NaN      NaN  \n",
       "621584            NaN      NaN  \n",
       "347820            NaN      NaN  \n",
       "771109            NaN      NaN  \n",
       "658144            NaN      NaN  \n",
       "387034            NaN      NaN  \n",
       "311770            NaN      NaN  \n",
       "241521            NaN      NaN  \n",
       "722811            NaN      NaN  \n",
       "362110            NaN      NaN  \n",
       "175227            NaN      NaN  \n",
       "104774            NaN      NaN  \n",
       "343519            NaN      NaN  \n",
       "471775            NaN      NaN  \n",
       "768610            NaN      NaN  \n",
       "266641            NaN      NaN  \n",
       "312579            NaN      NaN  \n",
       "408565            NaN      NaN  \n",
       "126400            NaN      NaN  \n",
       "468202            NaN      NaN  \n",
       "212128            NaN      NaN  \n",
       "38542             NaN      NaN  \n",
       "24511             NaN      NaN  \n",
       "220519            NaN      NaN  \n",
       "28508             NaN      NaN  \n",
       "...               ...      ...  \n",
       "213750            NaN      NaN  \n",
       "431907            NaN      NaN  \n",
       "274075            NaN      NaN  \n",
       "693537            NaN      NaN  \n",
       "148007            NaN      NaN  \n",
       "284998            NaN      NaN  \n",
       "761417            NaN      NaN  \n",
       "587313            NaN      NaN  \n",
       "226430            NaN      NaN  \n",
       "62602             NaN      NaN  \n",
       "464203            NaN      NaN  \n",
       "609207            NaN      NaN  \n",
       "440825            NaN      NaN  \n",
       "324790            NaN      NaN  \n",
       "194923            NaN      NaN  \n",
       "95488             NaN      NaN  \n",
       "708326            NaN      NaN  \n",
       "398246            NaN      NaN  \n",
       "266230            NaN      NaN  \n",
       "765350            NaN      NaN  \n",
       "163516            NaN      NaN  \n",
       "495581            NaN      NaN  \n",
       "504225            NaN      NaN  \n",
       "355541            NaN      NaN  \n",
       "195066            NaN      NaN  \n",
       "202418            NaN      NaN  \n",
       "502902            NaN      NaN  \n",
       "396237            NaN      NaN  \n",
       "166731            NaN      NaN  \n",
       "638276            NaN      NaN  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding_sampling(state_data_dir + coded_tweets, all_tweets, coding_sample_size, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wayback Machine Follower Parser\n",
    "Used along with [waybackpack](https://github.com/jsvine/waybackpack) to compile follower growth using Wayback Machine archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_follower_growth(pages_dir):\n",
    "  # start timer\n",
    "  start = time.time()\n",
    "  logger.info(\"Start...\")\n",
    "  \n",
    "  # intialize dataframe\n",
    "  follower_count_df = pd.DataFrame(columns=['date', 'follower_count', 'handle'])\n",
    "  \n",
    "  # Get the handles from dir present in dir of twitter pages pulled\n",
    "  handles = [name for name in os.listdir(os.path.expanduser(pages_dir)) if not name.startswith('.')]\n",
    "  handles = ['JebBush']\n",
    "  \n",
    "  # loop through each handle present and extract date and corresponding follower count\n",
    "  for handle in handles:\n",
    "    # dict with key:value equaling date:follower_count\n",
    "    follower_count_dict = {}\n",
    "    \n",
    "    # keep a list of dates failed for debugging purposes\n",
    "    failed_dates = []\n",
    "    passed_dates = []\n",
    "    \n",
    "    logger.info(\"Current Handle: %s\", handle)\n",
    "    \n",
    "    # make a list of the dates present in the wayback archive\n",
    "    dates = [date for date in os.listdir(os.path.expanduser(pages_dir + handle)) if not date.startswith('.')]\n",
    "    \n",
    "    # for each archive date find 'follower_count' element and extract total\n",
    "    for date in dates:\n",
    "      # intialize len of number and bool that keeps track of whether number has ended\n",
    "      num_len = 0\n",
    "      num = False\n",
    "      \n",
    "      # convert string to datetime object\n",
    "      count_date = datetime.strptime(date, \"%Y%m%d%H%M%S\") # currently not being utilized and converted after the fact\n",
    "      \n",
    "      # get the path of the specific date's archived html\n",
    "      page = pages_dir + handle + '/' + date + '/twitter.com' + '/' + handle\n",
    "      # open the file as a BeuatifulSoup object then convert it to an str for easier search indexing\n",
    "      soup = BeautifulSoup(open(os.path.expanduser(page)), 'html.parser')\n",
    "      soup = str(soup)\n",
    "      \n",
    "      # get the index of where the follower_count element is\n",
    "      init = soup.find('followers_count')\n",
    "      \n",
    "      # for debugging purposes keep track of failed follower_count search\n",
    "      if (init == -1):\n",
    "        failed_dates.append(date[0:4])\n",
    "        continue\n",
    "      \n",
    "      # iterate thru the string until a digit is reach\n",
    "      while (not num):\n",
    "        init+=1 # keep track of where the number's initial index\n",
    "        num = soup[init].isdigit() # will return whether current char is a digit\n",
    "      \n",
    "      # iterate thru the number until you reach a char that is not a digit\n",
    "      while (num):\n",
    "        num_len+=1 # keep track of the len of the number\n",
    "        num = soup[init:init+num_len].isdigit() # will return whether current char is a digit\n",
    "      \n",
    "      # slice the number out of the html string and convert to an int\n",
    "      follower_count = int(soup[init:init+num_len-1])\n",
    "      # store the follower count in a dict with a key:value of date:follower_count\n",
    "      follower_count_dict[date] = follower_count\n",
    "    \n",
    "    # initialize a temporary dataframe to store the current handle's follower_count growth\n",
    "    temp_df = pd.DataFrame.from_dict(follower_count_dict, orient='index')\n",
    "    temp_df.reset_index(level=0, inplace=True)\n",
    "    temp_df['handle'] = handle # add a col indicating corresponding handle\n",
    "    temp_df.columns = ['date', 'follower_count', 'handle'] # rename columns\n",
    "    \n",
    "    # append the new data to the comprehensive dataframe with the growth for all present candidates\n",
    "    follower_count_df = follower_count_df.append(temp_df)\n",
    "  logger.info('Number of failed follower_count element searches %d', len(failed_dates))\n",
    "  logger.info('Done!')\n",
    "  return follower_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate entries from wayback follower count data\n",
    "# requires data to be sorted\n",
    "def clean_duplicate_dates(follower_count_df):\n",
    "  # keep a list of each row to be dropped from the dataframe\n",
    "  entries_to_drop = []\n",
    "  # loop through each row\n",
    "  for index, row in follower_count_df.iterrows():\n",
    "    # take the current date and modify it to remove time \n",
    "    curr_date = int((row['date']) / 1000000) # use this line if date is saved as a int\n",
    "    # curr_date = row['date'][0:8] # use this line if date is saved as a string\n",
    "    \n",
    "    # the first row cannot be compared\n",
    "    if (index != 0):\n",
    "      # if prev MMDDYYYY matches the current add it to be removed\n",
    "      if (curr_date == prev_date[1]):\n",
    "        entries_to_drop.append(prev_date[0])\n",
    "    # set prev_date to current_date for next iteration\n",
    "    prev_date = (index, curr_date)\n",
    "  \n",
    "  logger.info(\"expected size of dataframe: %d\", len(follower_count_df) - len(entries_to_drop))\n",
    "  entries_to_keep = set(range(len(follower_count_df))) - set(entries_to_drop)\n",
    "  follower_count_df = follower_count_df.take(list(entries_to_keep))\n",
    "  logger.info(\"actual size of dataframe %d\", len(follower_count_df))\n",
    "  return follower_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code on how to save the data to an excel sheet and not lose id data\n",
    "# look over this is confused on how to save id field properly\n",
    "# writer = pd.ExcelWriter('coding_file.xlsx')\n",
    "# merged_sheets.id = merged_sheets.id.astype(str)\n",
    "# merged_sheets.to_excel(writer, 'total_sample', index=False, float_format='string')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets Pull Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file pathway variables an expand to HOME\n",
    "ca_data_dir = '~/Dropbox/Summer_of_Tweets/ca_working_sheets/'\n",
    "state_data_dir = '~/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/'\n",
    "pres_data_dir = '~/Dropbox/Summer_of_Tweets/working_sheets--THIS_IS_ACTUAL_DATA/'\n",
    "\n",
    "# the excel sheets containing the tweets\n",
    "cand_tweets = \"cand_tweets.xlsx\"\n",
    "spec_tweets = \"spec_tweets.xlsx\"\n",
    "rep_tweets = \"rep_tweets.xlsx\"\n",
    "state_tweets = \"state_tweets.xlsx\"\n",
    "coded_tweets = \"coding_file.xlsx\"\n",
    "pres_cand_tweets = \"Presidential_Tweets.xlsx\"\n",
    "pac_tweets = \"PAC_Tweets.xlsx\"\n",
    "\n",
    "# the excel file containing the accounts and its sheets\n",
    "twitter_list = \"Twitter_List.xlsx\" # this is the name of the metadata lists\n",
    "pres_cand_sheet = 'candidate'\n",
    "pac_sheet = 'pac'\n",
    "cand_sheet = \"cand\"\n",
    "spec_sheet = \"speculated\"\n",
    "rep_sheet = \"reps\"\n",
    "ca49_sheet = \"CA49\"\n",
    "state_sheets = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "all_handles = 'all'\n",
    "all_tweets = 'total_sample'\n",
    "\n",
    "coding_sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(ca_data_dir + cand_tweets, ca_data_dir + twitter_list, cand_sheet)\n",
    "print \n",
    "collect_data(ca_data_dir + spec_tweets, ca_data_dir + twitter_list, spec_sheet)\n",
    "print \n",
    "collect_data(ca_data_dir + rep_tweets, ca_data_dir + twitter_list, rep_sheet)\n",
    "print\n",
    "collect_data(ca_data_dir + cand_tweets, ca_data_dir + twitter_list, ca49_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collect_addition_data(ca_data_dir + cand_tweets, ca_data_dir + twitter_list, cand_sheet)\n",
    "print\n",
    "collect_addition_data(ca_data_dir + spec_tweets, ca_data_dir + twitter_list, spec_sheet)\n",
    "print\n",
    "collect_addition_data(ca_data_dir + rep_tweets, ca_data_dir + twitter_list, rep_sheet)\n",
    "print\n",
    "collect_addition_data(ca_data_dir + cand_tweets, ca_data_dir + twitter_list, ca49_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Start...\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/state_tweets.xlsx\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "/Users/SoloMune/miniconda2/envs/twitter-projects/lib/python2.7/site-packages/pandas/io/excel.py:329: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  **kwds)\n",
      "INFO:__main__:Downloading 0 tweets from melsonforsenate\n",
      "INFO:__main__:Downloading 0 tweets from billholtzclaw\n",
      "INFO:__main__:Downloading 1 tweets from SenatorAOrr\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorAOrr\n",
      "INFO:__main__:Downloading 0 tweets from PaulBussman\n",
      "INFO:__main__:Downloading 0 tweets from Larry_Stutts\n",
      "INFO:__main__:Downloading 5 tweets from steve17785344\n",
      "INFO:__main__:Updated new tweets on spreadsheet for steve17785344\n",
      "INFO:__main__:Downloading 0 tweets from ALConservative\n",
      "INFO:__main__:Downloading 4 tweets from senphilwilliams\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senphilwilliams\n",
      "INFO:__main__:Downloading 0 tweets from SenJimMcClendon\n",
      "INFO:__main__:Downloading 1 tweets from SenatorDelMarsh\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorDelMarsh\n",
      "INFO:__main__:Downloading 0 tweets from sengeralddial\n",
      "INFO:__main__:Downloading 3 tweets from sencamward\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sencamward\n",
      "INFO:__main__:Downloading 0 tweets from SladeBlackwell\n",
      "INFO:__main__:Downloading 2 tweets from shelnutt417\n",
      "INFO:__main__:Updated new tweets on spreadsheet for shelnutt417\n",
      "INFO:__main__:Downloading 0 tweets from alsenateprotem\n",
      "INFO:__main__:Downloading 0 tweets from SenGeraldAllen\n",
      "INFO:__main__:Downloading 2 tweets from senhanksanders\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senhanksanders\n",
      "INFO:__main__:Downloading 25 tweets from dick_brewbaker\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dick_brewbaker\n",
      "INFO:__main__:Downloading 2 tweets from sentomwhatley\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sentomwhatley\n",
      "INFO:__main__:Downloading 0 tweets from senbillybeasley\n",
      "INFO:__main__:Downloading 0 tweets from harriannesmith\n",
      "INFO:__main__:Downloading 0 tweets from clyde_chambliss\n",
      "INFO:__main__:Downloading 0 tweets from PittTrippman\n",
      "INFO:__main__:Downloading 0 tweets from vivian_figures\n",
      "INFO:__main__:Downloading 0 tweets from voteglover\n",
      "INFO:__main__:Downloading 0 tweets from billhightoweral\n",
      "INFO:__main__:Downloading 0 tweets from JohnMcMillan4\n",
      "INFO:__main__:Downloading 0 tweets from twinkleforal\n",
      "INFO:__main__:Downloading 45 tweets from JohnHMerrill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JohnHMerrill\n",
      "INFO:__main__:Downloading 1 tweets from jimzeigler\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jimzeigler\n",
      "INFO:__main__:Downloading 0 tweets from YoungBoozer\n",
      "INFO:__main__:Downloading 4 tweets from AGSteveMarshall\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AGSteveMarshall\n",
      "INFO:__main__:Downloading 5 tweets from GovernorKayIvey\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GovernorKayIvey\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 0 tweets from senatorcoghill\n",
      "INFO:__main__:Downloading 0 tweets from click_bishop\n",
      "INFO:__main__:Downloading 0 tweets from akshelleyhughes\n",
      "INFO:__main__:Downloading 3 tweets from wielechowski\n",
      "INFO:__main__:Updated new tweets on spreadsheet for wielechowski\n",
      "INFO:__main__:Downloading 0 tweets from senbertagardner\n",
      "INFO:__main__:Downloading 0 tweets from tombegich\n",
      "INFO:__main__:Downloading 0 tweets from miacostelloak\n",
      "INFO:__main__:Downloading 0 tweets from SenKevinMeyer\n",
      "INFO:__main__:Downloading 0 tweets from pmiccic\n",
      "INFO:__main__:Downloading 0 tweets from senstedman\n",
      "INFO:__main__:Downloading 3 tweets from AkGovBillWalker\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AkGovBillWalker\n",
      "INFO:__main__:Downloading 0 tweets from ltgovmallott\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 5 tweets from tomforese\n",
      "INFO:__main__:Updated new tweets on spreadsheet for tomforese\n",
      "INFO:__main__:Downloading 0 tweets from markwkillian\n",
      "INFO:__main__:Downloading 6 tweets from SecretaryReagan\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SecretaryReagan\n",
      "INFO:__main__:Downloading 4 tweets from _dianedouglas\n",
      "INFO:__main__:Updated new tweets on spreadsheet for _dianedouglas\n",
      "INFO:__main__:Downloading 0 tweets from AZTreasurer\n",
      "INFO:__main__:Downloading 7 tweets from GeneralBrnovich\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GeneralBrnovich\n",
      "INFO:__main__:Downloading 18 tweets from dougducey\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dougducey\n",
      "INFO:__main__:Downloading 4 tweets from FannKfann\n",
      "INFO:__main__:Updated new tweets on spreadsheet for FannKfann\n",
      "INFO:__main__:Downloading 46 tweets from Dalessandro4AZ\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Dalessandro4AZ\n",
      "INFO:__main__:Downloading 0 tweets from RepOtondo\n",
      "INFO:__main__:Downloading 0 tweets from SylviaAllenAZ\n",
      "INFO:__main__:Downloading 7 tweets from jamescita\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jamescita\n",
      "INFO:__main__:Downloading 0 tweets from pratt4az\n",
      "INFO:__main__:Downloading 24 tweets from SteveFarleyAZ\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SteveFarleyAZ\n",
      "INFO:__main__:Downloading 1 tweets from Bradley4AZ\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Bradley4AZ\n",
      "INFO:__main__:Downloading 2 tweets from senstevesmith\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senstevesmith\n",
      "INFO:__main__:Downloading 2 tweets from votewarren\n",
      "INFO:__main__:Updated new tweets on spreadsheet for votewarren\n",
      "INFO:__main__:Downloading 0 tweets from SineKerr\n",
      "INFO:__main__:Downloading 3 tweets from NancyBarto\n",
      "INFO:__main__:Updated new tweets on spreadsheet for NancyBarto\n",
      "INFO:__main__:Downloading 0 tweets from DaveFarnsworth_\n",
      "INFO:__main__:Downloading 3 tweets from seanbowie\n",
      "INFO:__main__:Updated new tweets on spreadsheet for seanbowie\n",
      "INFO:__main__:Downloading 1 tweets from KimberlyYeeAZ\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KimberlyYeeAZ\n",
      "INFO:__main__:Downloading 0 tweets from RickGray\n",
      "INFO:__main__:Downloading 0 tweets from AzLD22\n",
      "INFO:__main__:Downloading 0 tweets from katiehobbs\n",
      "INFO:__main__:Downloading 0 tweets from bob_worsley\n",
      "INFO:__main__:Downloading 30 tweets from mendezforaz\n",
      "INFO:__main__:Updated new tweets on spreadsheet for mendezforaz\n",
      "INFO:__main__:Downloading 8 tweets from Miranda4Arizona\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Miranda4Arizona\n",
      "INFO:__main__:Downloading 12 tweets from KateMcGeeAz\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KateMcGeeAz\n",
      "INFO:__main__:Downloading 4 tweets from SenQuezada29\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenQuezada29\n",
      "INFO:__main__:Downloading 0 tweets from MezaArizona\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 3239 tweets from AsaHutchinson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AsaHutchinson\n",
      "INFO:__main__:Downloading 3247 tweets from LtGovTimGriffin\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LtGovTimGriffin\n",
      "INFO:__main__:Downloading 3245 tweets from AGRutledge\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AGRutledge\n",
      "INFO:__main__:Downloading 1866 tweets from Mark_Martin\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Mark_Martin\n",
      "INFO:__main__:Downloading 3232 tweets from JimHendren1\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JimHendren1\n",
      "INFO:__main__:Downloading 1235 tweets from Cecilebledsoe\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Cecilebledsoe\n",
      "INFO:__main__:Downloading 1 tweets from ulindsey\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ulindsey\n",
      "INFO:__main__:Downloading 3113 tweets from BryanBKing\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BryanBKing\n",
      "INFO:__main__:Downloading 1385 tweets from G_Stubblefield\n",
      "INFO:__main__:Updated new tweets on spreadsheet for G_Stubblefield\n",
      "INFO:__main__:Downloading 1919 tweets from lancereads\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lancereads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading 124 tweets from TerryRice6\n",
      "INFO:__main__:Updated new tweets on spreadsheet for TerryRice6\n",
      "INFO:__main__:Downloading 767 tweets from bmaloch\n",
      "INFO:__main__:Updated new tweets on spreadsheet for bmaloch\n",
      "INFO:__main__:Downloading 117 tweets from AlanClark4AR\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AlanClark4AR\n",
      "INFO:__main__:Downloading 3178 tweets from David_J_Sanders\n",
      "INFO:__main__:Updated new tweets on spreadsheet for David_J_Sanders\n",
      "INFO:__main__:Downloading 2 tweets from ScottFlippo\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ScottFlippo\n",
      "INFO:__main__:Downloading 3234 tweets from ARSenMissyIrvin\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ARSenMissyIrvin\n",
      "INFO:__main__:Downloading 3229 tweets from Linda4Senate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Linda4Senate\n",
      "INFO:__main__:Downloading 943 tweets from cooper4senate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for cooper4senate\n",
      "INFO:__main__:Downloading 42 tweets from WallaceARsen5\n",
      "INFO:__main__:Updated new tweets on spreadsheet for WallaceARsen5\n",
      "INFO:__main__:Downloading 41 tweets from RonRCaldwell\n",
      "INFO:__main__:Updated new tweets on spreadsheet for RonRCaldwell\n",
      "INFO:__main__:Downloading 548 tweets from KeithIngramAR\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KeithIngramAR\n",
      "INFO:__main__:Downloading 0 tweets from SenatorFlowers\n",
      "INFO:__main__:Downloading 763 tweets from trent_garner\n",
      "INFO:__main__:Updated new tweets on spreadsheet for trent_garner\n",
      "INFO:__main__:Downloading 3194 tweets from dismang\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dismang\n",
      "INFO:__main__:Downloading 3225 tweets from xjelliott\n",
      "INFO:__main__:Updated new tweets on spreadsheet for xjelliott\n",
      "INFO:__main__:Downloading 1590 tweets from 1willbond\n",
      "INFO:__main__:Updated new tweets on spreadsheet for 1willbond\n",
      "INFO:__main__:Downloading 1456 tweets from SenJHutch\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenJHutch\n",
      "INFO:__main__:Downloading 101 tweets from JaneEnglishAR\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JaneEnglishAR\n",
      "INFO:__main__:Downloading 3246 tweets from jasonrapert\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jasonrapert\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 541 tweets from ilike_mike\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ilike_mike\n",
      "INFO:__main__:Downloading 203 tweets from billdoddca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for billdoddca\n",
      "INFO:__main__:Downloading 0 tweets from senatorgalgiani\n",
      "INFO:__main__:Downloading 710 tweets from DrPanMD\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DrPanMD\n",
      "INFO:__main__:Downloading 91 tweets from steve_glazer\n",
      "INFO:__main__:Updated new tweets on spreadsheet for steve_glazer\n",
      "INFO:__main__:Downloading 105 tweets from nancyskinnerca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for nancyskinnerca\n",
      "INFO:__main__:Downloading 210 tweets from BobWieckowskiCA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BobWieckowskiCA\n",
      "INFO:__main__:Downloading 914 tweets from scott_wiener\n",
      "INFO:__main__:Updated new tweets on spreadsheet for scott_wiener\n",
      "INFO:__main__:Downloading 197 tweets from Jimbealljr\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Jimbealljr\n",
      "INFO:__main__:Downloading 0 tweets from billmonning\n",
      "INFO:__main__:Downloading 172 tweets from hertzieLA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for hertzieLA\n",
      "INFO:__main__:Downloading 96 tweets from SenHannahBeth\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenHannahBeth\n",
      "INFO:__main__:Downloading 314 tweets from senatorleyva\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorleyva\n",
      "INFO:__main__:Downloading 351 tweets from dredhernandez\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dredhernandez\n",
      "INFO:__main__:Downloading 442 tweets from kdeleon\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kdeleon\n",
      "INFO:__main__:Downloading 192 tweets from portantino\n",
      "INFO:__main__:Updated new tweets on spreadsheet for portantino\n",
      "INFO:__main__:Downloading 199 tweets from BenAllenCA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BenAllenCA\n",
      "INFO:__main__:Downloading 97 tweets from henrysternca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for henrysternca\n",
      "INFO:__main__:Downloading 71 tweets from senatornewmanca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatornewmanca\n",
      "INFO:__main__:Downloading 167 tweets from hollyjmitchell\n",
      "INFO:__main__:Updated new tweets on spreadsheet for hollyjmitchell\n",
      "INFO:__main__:Downloading 453 tweets from generalroth\n",
      "INFO:__main__:Updated new tweets on spreadsheet for generalroth\n",
      "INFO:__main__:Downloading 202 tweets from senricardolara\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senricardolara\n",
      "INFO:__main__:Downloading 233 tweets from stevebradford\n",
      "INFO:__main__:Updated new tweets on spreadsheet for stevebradford\n",
      "INFO:__main__:Downloading 359 tweets from toniatkins\n",
      "INFO:__main__:Updated new tweets on spreadsheet for toniatkins\n",
      "INFO:__main__:Downloading 0 tweets from benhueso\n",
      "INFO:__main__:Downloading 179 tweets from senatorpatbates\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorpatbates\n",
      "INFO:__main__:Downloading 105 tweets from joelandersonca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for joelandersonca\n",
      "INFO:__main__:Downloading 0 tweets from TomBerryhill\n",
      "INFO:__main__:Downloading 63 tweets from AnthonyCannella\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AnthonyCannella\n",
      "INFO:__main__:Downloading 90 tweets from JeanFuller\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JeanFuller\n",
      "INFO:__main__:Downloading 151 tweets from TedGaines\n",
      "INFO:__main__:Updated new tweets on spreadsheet for TedGaines\n",
      "INFO:__main__:Downloading 162 tweets from senatormoorlach\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatormoorlach\n",
      "INFO:__main__:Downloading 45 tweets from MikeMorrellGOP\n",
      "INFO:__main__:Updated new tweets on spreadsheet for MikeMorrellGOP\n",
      "INFO:__main__:Downloading 32 tweets from janetnguyenca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for janetnguyenca\n",
      "INFO:__main__:Downloading 59 tweets from casenatorjim\n",
      "INFO:__main__:Updated new tweets on spreadsheet for casenatorjim\n",
      "INFO:__main__:Downloading 78 tweets from SenJeffStone\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenJeffStone\n",
      "INFO:__main__:Downloading 162 tweets from senandyvidak\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senandyvidak\n",
      "INFO:__main__:Downloading 106 tweets from scottwilkca\n",
      "INFO:__main__:Updated new tweets on spreadsheet for scottwilkca\n",
      "INFO:__main__:Downloading 363 tweets from GavinNewsom\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GavinNewsom\n",
      "INFO:__main__:Downloading 493 tweets from JohnChiangCA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JohnChiangCA\n",
      "INFO:__main__:Downloading 18 tweets from jerrybrowngov\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jerrybrowngov\n",
      "INFO:__main__:Downloading 322 tweets from AGBecerra\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AGBecerra\n",
      "INFO:__main__:Downloading 162 tweets from BettyYeeforCA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BettyYeeforCA\n",
      "INFO:__main__:Downloading 477 tweets from CA_DaveJones\n",
      "INFO:__main__:Updated new tweets on spreadsheet for CA_DaveJones\n",
      "INFO:__main__:Downloading 12 tweets from TomTorlakson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for TomTorlakson\n",
      "INFO:__main__:Downloading 864 tweets from AlexPadilla4CA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AlexPadilla4CA\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 388 tweets from CynthiaHCoffman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for CynthiaHCoffman\n",
      "INFO:__main__:Downloading 3195 tweets from COSecofState\n",
      "INFO:__main__:Updated new tweets on spreadsheet for COSecofState\n",
      "INFO:__main__:Downloading 587 tweets from WalkerStapleton\n",
      "INFO:__main__:Updated new tweets on spreadsheet for WalkerStapleton\n",
      "INFO:__main__:Downloading 2809 tweets from hickforco\n",
      "INFO:__main__:Updated new tweets on spreadsheet for hickforco\n",
      "INFO:__main__:Downloading 513 tweets from DonnaLynneCO\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DonnaLynneCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading 1518 tweets from JerrySonnenberg\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JerrySonnenberg\n",
      "INFO:__main__:Downloading 3222 tweets from SenatorGrantham\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorGrantham\n",
      "INFO:__main__:Downloading 471 tweets from Leroy_Garcia\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Leroy_Garcia\n",
      "INFO:__main__:Downloading 377 tweets from jimsmallwood\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jimsmallwood\n",
      "INFO:__main__:Downloading 3225 tweets from KerryDonovanSD5\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KerryDonovanSD5\n",
      "INFO:__main__:Downloading 3196 tweets from SCOTTFORCOLO\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SCOTTFORCOLO\n",
      "INFO:__main__:Downloading 586 tweets from CapitalCowboy\n",
      "INFO:__main__:Updated new tweets on spreadsheet for CapitalCowboy\n",
      "INFO:__main__:Downloading 3138 tweets from owenjhill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for owenjhill\n",
      "INFO:__main__:Downloading 184 tweets from Merrifield_SD11\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Merrifield_SD11\n",
      "INFO:__main__:Downloading 119 tweets from SenBobGardner\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenBobGardner\n",
      "INFO:__main__:Downloading 1818 tweets from KefalasJohn\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KefalasJohn\n",
      "INFO:__main__:Downloading 786 tweets from KevinLundberg\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KevinLundberg\n",
      "INFO:__main__:Downloading 645 tweets from NevilleforCO\n",
      "INFO:__main__:Updated new tweets on spreadsheet for NevilleforCO\n",
      "INFO:__main__:Downloading 826 tweets from SteveFenberg\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SteveFenberg\n",
      "INFO:__main__:Downloading 1812 tweets from Zenzinger_AtoZ\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Zenzinger_AtoZ\n",
      "INFO:__main__:Downloading 244 tweets from CheriJahn\n",
      "INFO:__main__:Updated new tweets on spreadsheet for CheriJahn\n",
      "INFO:__main__:Downloading 1405 tweets from domoreno\n",
      "INFO:__main__:Updated new tweets on spreadsheet for domoreno\n",
      "INFO:__main__:Downloading 3195 tweets from SenAndyKerr\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenAndyKerr\n",
      "INFO:__main__:Downloading 68 tweets from VickiMarble\n",
      "INFO:__main__:Updated new tweets on spreadsheet for VickiMarble\n",
      "INFO:__main__:Downloading 1581 tweets from KevinPriola\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KevinPriola\n",
      "INFO:__main__:Downloading 587 tweets from DanielKagan\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DanielKagan\n",
      "INFO:__main__:Downloading 180 tweets from JackTateCO\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JackTateCO\n",
      "INFO:__main__:Downloading 1223 tweets from nancytodd28\n",
      "INFO:__main__:Updated new tweets on spreadsheet for nancytodd28\n",
      "INFO:__main__:Downloading 3217 tweets from senrhondafields\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senrhondafields\n",
      "INFO:__main__:Downloading 3087 tweets from Chris_Holbert\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Chris_Holbert\n",
      "INFO:__main__:Downloading 1335 tweets from AguilarFor32\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AguilarFor32\n",
      "INFO:__main__:Downloading 2147 tweets from COSenWilliams\n",
      "INFO:__main__:Updated new tweets on spreadsheet for COSenWilliams\n",
      "INFO:__main__:Downloading 2147 tweets from SenGuzman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenGuzman\n",
      "INFO:__main__:Downloading 824 tweets from SenatorCrowder\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorCrowder\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 0 tweets from timlarson4ct\n",
      "INFO:__main__:Downloading 1 tweets from cassano4senate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for cassano4senate\n",
      "INFO:__main__:Downloading 250 tweets from bethbye5\n",
      "INFO:__main__:Updated new tweets on spreadsheet for bethbye5\n",
      "INFO:__main__:Downloading 29 tweets from terrygerratana\n",
      "INFO:__main__:Updated new tweets on spreadsheet for terrygerratana\n",
      "INFO:__main__:Downloading 16 tweets from senatorkissel\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorkissel\n",
      "INFO:__main__:Downloading 23 tweets from senatorwitkos\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorwitkos\n",
      "INFO:__main__:Downloading 274 tweets from 10sddem\n",
      "INFO:__main__:Updated new tweets on spreadsheet for 10sddem\n",
      "INFO:__main__:Downloading 78 tweets from tedkennedyjr\n",
      "INFO:__main__:Updated new tweets on spreadsheet for tedkennedyjr\n",
      "INFO:__main__:Downloading 0 tweets from senatorsuzio\n",
      "INFO:__main__:Downloading 3 tweets from joemarkley\n",
      "INFO:__main__:Updated new tweets on spreadsheet for joemarkley\n",
      "INFO:__main__:Downloading 182 tweets from sengeorgelogan\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sengeorgelogan\n",
      "INFO:__main__:Downloading 0 tweets from heatherssomers\n",
      "INFO:__main__:Downloading 748 tweets from cathyosten\n",
      "INFO:__main__:Updated new tweets on spreadsheet for cathyosten\n",
      "INFO:__main__:Downloading 60 tweets from senatorformica\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorformica\n",
      "INFO:__main__:Downloading 59 tweets from 21kevinkelly\n",
      "INFO:__main__:Updated new tweets on spreadsheet for 21kevinkelly\n",
      "INFO:__main__:Downloading 0 tweets from senator_edgomes\n",
      "INFO:__main__:Downloading 28 tweets from senatormike\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatormike\n",
      "INFO:__main__:Downloading 1115 tweets from senatorduff\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorduff\n",
      "INFO:__main__:Downloading 39 tweets from toniboucher\n",
      "INFO:__main__:Updated new tweets on spreadsheet for toniboucher\n",
      "INFO:__main__:Downloading 34 tweets from sencarloleone\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sencarloleone\n",
      "INFO:__main__:Downloading 52 tweets from senatorhwang\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorhwang\n",
      "INFO:__main__:Downloading 144 tweets from maeflexer\n",
      "INFO:__main__:Updated new tweets on spreadsheet for maeflexer\n",
      "INFO:__main__:Downloading 0 tweets from martinforsenate\n",
      "INFO:__main__:Downloading 68 tweets from eric_berthel\n",
      "INFO:__main__:Updated new tweets on spreadsheet for eric_berthel\n",
      "INFO:__main__:Downloading 19 tweets from senatorlinares\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorlinares\n",
      "INFO:__main__:Downloading 72 tweets from senatorfasano\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorfasano\n",
      "INFO:__main__:Downloading 8 tweets from tonyguglielmo\n",
      "INFO:__main__:Updated new tweets on spreadsheet for tonyguglielmo\n",
      "INFO:__main__:Downloading 41 tweets from agjepsen\n",
      "INFO:__main__:Updated new tweets on spreadsheet for agjepsen\n",
      "INFO:__main__:Downloading 22 tweets from kevinlembo\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kevinlembo\n",
      "INFO:__main__:Downloading 665 tweets from GovMalloyOffice\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GovMalloyOffice\n",
      "INFO:__main__:Downloading 219 tweets from LGWyman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LGWyman\n",
      "INFO:__main__:Downloading 220 tweets from SOTSMerrill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SOTSMerrill\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 1265 tweets from Matt_Denn\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Matt_Denn\n",
      "INFO:__main__:Downloading 0 tweets from TrinidadN2016\n",
      "INFO:__main__:Downloading 17 tweets from AuditorWagner\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AuditorWagner\n",
      "INFO:__main__:Downloading 376 tweets from KenSimpler\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KenSimpler\n",
      "INFO:__main__:Downloading 2895 tweets from JohnCarneyDE\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JohnCarneyDE\n",
      "INFO:__main__:Downloading 706 tweets from bethanyhalllong\n",
      "INFO:__main__:Updated new tweets on spreadsheet for bethanyhalllong\n",
      "INFO:__main__:Downloading 75 tweets from MargaretRHenry\n",
      "INFO:__main__:Updated new tweets on spreadsheet for MargaretRHenry\n",
      "INFO:__main__:Downloading 33 tweets from Greg_Lavelle\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Greg_Lavelle\n",
      "INFO:__main__:Downloading 15 tweets from SenCloutier\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenCloutier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading 2036 tweets from LopezforDE\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LopezforDE\n",
      "INFO:__main__:Downloading 386 tweets from Delcollo4DE\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Delcollo4DE\n",
      "INFO:__main__:Downloading 1 tweets from SokolaDavid\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SokolaDavid\n",
      "INFO:__main__:Downloading 79 tweets from HansenForSenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for HansenForSenate\n",
      "INFO:__main__:Downloading 3199 tweets from BryanTownsendDE\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BryanTownsendDE\n",
      "INFO:__main__:Downloading 1481 tweets from NicolePoore12\n",
      "INFO:__main__:Updated new tweets on spreadsheet for NicolePoore12\n",
      "INFO:__main__:Downloading 32 tweets from Lawson4Senate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Lawson4Senate\n",
      "INFO:__main__:Downloading 507 tweets from ColinBonini\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ColinBonini\n",
      "INFO:__main__:Downloading 789 tweets from BrianPettyjohn\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BrianPettyjohn\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 106 tweets from AGPamBondi\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AGPamBondi\n",
      "INFO:__main__:Downloading 301 tweets from JimmyPatronis\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JimmyPatronis\n",
      "INFO:__main__:Downloading 562 tweets from adamputnam\n",
      "INFO:__main__:Updated new tweets on spreadsheet for adamputnam\n",
      "INFO:__main__:Downloading 16 tweets from cissy_proctor\n",
      "INFO:__main__:Updated new tweets on spreadsheet for cissy_proctor\n",
      "INFO:__main__:Downloading 36 tweets from KenDetzner\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KenDetzner\n",
      "INFO:__main__:Downloading 484 tweets from FLGovScott\n",
      "INFO:__main__:Updated new tweets on spreadsheet for FLGovScott\n",
      "INFO:__main__:Downloading 107 tweets from LopezCantera\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LopezCantera\n",
      "INFO:__main__:Downloading 3 tweets from dennisbaxley\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dennisbaxley\n",
      "INFO:__main__:Downloading 173 tweets from AaronPBean\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AaronPBean\n",
      "INFO:__main__:Downloading 135 tweets from lizbethkb\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lizbethkb\n",
      "INFO:__main__:Downloading 209 tweets from Rob_Bradley\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Rob_Bradley\n",
      "INFO:__main__:Downloading 767 tweets from JeffreyBrandes\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JeffreyBrandes\n",
      "INFO:__main__:Downloading 38 tweets from oscarjb2\n",
      "INFO:__main__:Updated new tweets on spreadsheet for oscarjb2\n",
      "INFO:__main__:Downloading 0 tweets from DougBroxson\n",
      "INFO:__main__:Downloading 0 tweets from SenCampbellD38\n",
      "INFO:__main__:Downloading 282 tweets from FarmerForFLSen\n",
      "INFO:__main__:Updated new tweets on spreadsheet for FarmerForFLSen\n",
      "INFO:__main__:Downloading 67 tweets from anitere_flores\n",
      "INFO:__main__:Updated new tweets on spreadsheet for anitere_flores\n",
      "INFO:__main__:Downloading 184 tweets from SenatorGainer\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorGainer\n",
      "INFO:__main__:Downloading 73 tweets from BillGalvano\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BillGalvano\n",
      "INFO:__main__:Downloading 184 tweets from SenReneGarcia\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenReneGarcia\n",
      "INFO:__main__:Downloading 63 tweets from SenAudrey2eet\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenAudrey2eet\n",
      "INFO:__main__:Downloading 349 tweets from denisegrimsley\n",
      "INFO:__main__:Updated new tweets on spreadsheet for denisegrimsley\n",
      "INFO:__main__:Downloading 85 tweets from DorothyHukill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DorothyHukill\n",
      "INFO:__main__:Downloading 53 tweets from TravisJHutson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for TravisJHutson\n",
      "INFO:__main__:Downloading 22 tweets from TomLeeFL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for TomLeeFL\n",
      "INFO:__main__:Downloading 211 tweets from debbie_mayfield\n",
      "INFO:__main__:Updated new tweets on spreadsheet for debbie_mayfield\n",
      "INFO:__main__:Downloading 59 tweets from joenegronfl\n",
      "INFO:__main__:Updated new tweets on spreadsheet for joenegronfl\n",
      "INFO:__main__:Downloading 96 tweets from Kathleen4SWFL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Kathleen4SWFL\n",
      "INFO:__main__:Downloading 98 tweets from KeithPerryFL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KeithPerryFL\n",
      "INFO:__main__:Downloading 0 tweets from Powell4Senate\n",
      "INFO:__main__:Downloading 2 tweets from KevinRader\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KevinRader\n",
      "INFO:__main__:Downloading 76 tweets from JoseJavierJJR\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JoseJavierJJR\n",
      "INFO:__main__:Downloading 6 tweets from darrylrouson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for darrylrouson\n",
      "INFO:__main__:Downloading 0 tweets from DSimmonsFL\n",
      "INFO:__main__:Downloading 4 tweets from WiltonSimpson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for WiltonSimpson\n",
      "INFO:__main__:Downloading 15 tweets from gregsteube\n",
      "INFO:__main__:Updated new tweets on spreadsheet for gregsteube\n",
      "INFO:__main__:Downloading 261 tweets from LindaStewartFL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LindaStewartFL\n",
      "INFO:__main__:Downloading 689 tweets from Annette_Taddeo\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Annette_Taddeo\n",
      "INFO:__main__:Downloading 14 tweets from SenatorThurston\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorThurston\n",
      "INFO:__main__:Downloading 3 tweets from VicTorres_FL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for VicTorres_FL\n",
      "INFO:__main__:Downloading 222 tweets from DanaYoungFL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DanaYoungFL\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 9 tweets from repbenwatson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for repbenwatson\n",
      "INFO:__main__:Downloading 0 tweets from lester_jackson\n",
      "INFO:__main__:Downloading 0 tweets from williamligon\n",
      "INFO:__main__:Downloading 124 tweets from curt_thompson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for curt_thompson\n",
      "INFO:__main__:Downloading 1459 tweets from senatorjen\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorjen\n",
      "INFO:__main__:Downloading 82 tweets from harper4georgia\n",
      "INFO:__main__:Updated new tweets on spreadsheet for harper4georgia\n",
      "INFO:__main__:Downloading 151 tweets from pkmartiniv\n",
      "INFO:__main__:Updated new tweets on spreadsheet for pkmartiniv\n",
      "INFO:__main__:Downloading 0 tweets from emanueldjones\n",
      "INFO:__main__:Downloading 257 tweets from drdeanburke\n",
      "INFO:__main__:Updated new tweets on spreadsheet for drdeanburke\n",
      "INFO:__main__:Downloading 0 tweets from freddie_sims\n",
      "INFO:__main__:Downloading 1 tweets from senatorgregkirk\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorgregkirk\n",
      "INFO:__main__:Downloading 20 tweets from BruceThompsonGA\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BruceThompsonGA\n",
      "INFO:__main__:Downloading 4 tweets from sen_ed_harbison\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sen_ed_harbison\n",
      "INFO:__main__:Downloading 0 tweets from voteharbin\n",
      "INFO:__main__:Downloading 2 tweets from BlakeTillery\n",
      "INFO:__main__:Updated new tweets on spreadsheet for BlakeTillery\n",
      "INFO:__main__:Downloading 0 tweets from beachforsenate\n",
      "INFO:__main__:Downloading 0 tweets from Brandon Beach\n",
      "INFO:__main__:Downloading 8 tweets from stone4gasenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for stone4gasenate\n",
      "INFO:__main__:Downloading 0 tweets from votelee\n",
      "INFO:__main__:Downloading 6 tweets from burtjonesforga\n",
      "INFO:__main__:Updated new tweets on spreadsheet for burtjonesforga\n",
      "INFO:__main__:Downloading 0 tweets from sendavidlucas\n",
      "INFO:__main__:Downloading 585 tweets from williamsforga\n",
      "INFO:__main__:Updated new tweets on spreadsheet for williamsforga\n",
      "INFO:__main__:Downloading 0 tweets from vote_matt_brass\n",
      "INFO:__main__:Downloading 1718 tweets from JoshMcKoon\n",
      "INFO:__main__:Updated new tweets on spreadsheet for JoshMcKoon\n",
      "INFO:__main__:Downloading 21 tweets from mdugan30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Updated new tweets on spreadsheet for mdugan30\n",
      "INFO:__main__:Downloading 3 tweets from kirkpatrickdk\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kirkpatrickdk\n",
      "INFO:__main__:Downloading 133 tweets from valenciaseay\n",
      "INFO:__main__:Updated new tweets on spreadsheet for valenciaseay\n",
      "INFO:__main__:Downloading 11 tweets from senatordjames\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatordjames\n",
      "INFO:__main__:Downloading 254 tweets from sennanorrock\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sennanorrock\n",
      "INFO:__main__:Downloading 2 tweets from horacenatate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for horacenatate\n",
      "INFO:__main__:Downloading 201 tweets from NikemaForSenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for NikemaForSenate\n",
      "INFO:__main__:Downloading 13 tweets from fran_millar\n",
      "INFO:__main__:Updated new tweets on spreadsheet for fran_millar\n",
      "INFO:__main__:Downloading 73 tweets from senstevehenson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senstevehenson\n",
      "INFO:__main__:Downloading 235 tweets from elenaparent\n",
      "INFO:__main__:Updated new tweets on spreadsheet for elenaparent\n",
      "INFO:__main__:Downloading 0 tweets from tonyapanderson\n",
      "INFO:__main__:Downloading 0 tweets from gail_davenport\n",
      "INFO:__main__:Downloading 336 tweets from Renee_Unterman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Renee_Unterman\n",
      "INFO:__main__:Downloading 0 tweets from billcowsert\n",
      "INFO:__main__:Downloading 74 tweets from davidshafer\n",
      "INFO:__main__:Updated new tweets on spreadsheet for davidshafer\n",
      "INFO:__main__:Downloading 3 tweets from Butch_Miller\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Butch_Miller\n",
      "INFO:__main__:Downloading 54 tweets from senjwilkinson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senjwilkinson\n",
      "INFO:__main__:Downloading 14 tweets from stephengooch\n",
      "INFO:__main__:Updated new tweets on spreadsheet for stephengooch\n",
      "INFO:__main__:Downloading 47 tweets from huffgasenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for huffgasenate\n",
      "INFO:__main__:Downloading 37 tweets from chuck_payne\n",
      "INFO:__main__:Updated new tweets on spreadsheet for chuck_payne\n",
      "INFO:__main__:Downloading 243 tweets from sengloriabutler\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sengloriabutler\n",
      "INFO:__main__:Downloading 72 tweets from johnalbers\n",
      "INFO:__main__:Updated new tweets on spreadsheet for johnalbers\n",
      "INFO:__main__:Downloading 315 tweets from ChrisCarr_Ga\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ChrisCarr_Ga\n",
      "INFO:__main__:Downloading 132 tweets from GovernorDeal\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GovernorDeal\n",
      "INFO:__main__:Downloading 924 tweets from CaseyCagle\n",
      "INFO:__main__:Updated new tweets on spreadsheet for CaseyCagle\n",
      "INFO:__main__:Downloading 1672 tweets from briankempga\n",
      "INFO:__main__:Updated new tweets on spreadsheet for briankempga\n",
      "INFO:__main__:Downloading 476 tweets from suptwoods\n",
      "INFO:__main__:Updated new tweets on spreadsheet for suptwoods\n",
      "INFO:__main__:Downloading 802 tweets from ralphhudgens\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ralphhudgens\n",
      "INFO:__main__:Downloading 688 tweets from butler4ga\n",
      "INFO:__main__:Updated new tweets on spreadsheet for butler4ga\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 9 tweets from kaialiikahele\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kaialiikahele\n",
      "INFO:__main__:Downloading 0 tweets from senruderman\n",
      "INFO:__main__:Downloading 128 tweets from DrJoshGreen\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DrJoshGreen\n",
      "INFO:__main__:Downloading 1069 tweets from GilKAOGG\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GilKAOGG\n",
      "INFO:__main__:Downloading 4 tweets from rozbaker\n",
      "INFO:__main__:Updated new tweets on spreadsheet for rozbaker\n",
      "INFO:__main__:Downloading 86 tweets from jkalanienglish\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jkalanienglish\n",
      "INFO:__main__:Downloading 0 tweets from ronkouchi\n",
      "INFO:__main__:Downloading 0 tweets from stanleypchang\n",
      "INFO:__main__:Downloading 3 tweets from breeneharimoto\n",
      "INFO:__main__:Updated new tweets on spreadsheet for breeneharimoto\n",
      "INFO:__main__:Downloading 203 tweets from willespero\n",
      "INFO:__main__:Updated new tweets on spreadsheet for willespero\n",
      "INFO:__main__:Downloading 109 tweets from senmikegabbard\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senmikegabbard\n",
      "INFO:__main__:Downloading 59 tweets from senmaile\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senmaile\n",
      "INFO:__main__:Downloading 59 tweets from donovandelacruz\n",
      "INFO:__main__:Updated new tweets on spreadsheet for donovandelacruz\n",
      "INFO:__main__:Downloading 196 tweets from jilltokuda\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jilltokuda\n",
      "INFO:__main__:Downloading 0 tweets from SenLauraThielen\n",
      "INFO:__main__:Downloading 217 tweets from dougchinforhi\n",
      "INFO:__main__:Updated new tweets on spreadsheet for dougchinforhi\n",
      "INFO:__main__:Downloading 22 tweets from atghigov\n",
      "INFO:__main__:Updated new tweets on spreadsheet for atghigov\n",
      "INFO:__main__:Downloading 1206 tweets from GovHawaii\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GovHawaii\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 1112 tweets from stevevickidaho\n",
      "INFO:__main__:Updated new tweets on spreadsheet for stevevickidaho\n",
      "INFO:__main__:Downloading 497 tweets from senbobnonini\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senbobnonini\n",
      "INFO:__main__:Downloading 75 tweets from marysouzaidaho\n",
      "INFO:__main__:Updated new tweets on spreadsheet for marysouzaidaho\n",
      "INFO:__main__:Downloading 9 tweets from idsendantheman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for idsendantheman\n",
      "INFO:__main__:Downloading 74 tweets from idaho4johnson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for idaho4johnson\n",
      "INFO:__main__:Downloading 20 tweets from thaynforsenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for thaynforsenate\n",
      "INFO:__main__:Downloading 56 tweets from senabbylee\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senabbylee\n",
      "INFO:__main__:Downloading 612 tweets from jimriceidaho\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jimriceidaho\n",
      "INFO:__main__:Downloading 16 tweets from lakeytodd\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lakeytodd\n",
      "INFO:__main__:Downloading 1476 tweets from marvhagedorn\n",
      "INFO:__main__:Updated new tweets on spreadsheet for marvhagedorn\n",
      "INFO:__main__:Downloading 5 tweets from Burgoyne4Senate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Burgoyne4Senate\n",
      "INFO:__main__:Downloading 16 tweets from jordansen17\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jordansen17\n",
      "INFO:__main__:Downloading 129 tweets from wardengelking\n",
      "INFO:__main__:Updated new tweets on spreadsheet for wardengelking\n",
      "INFO:__main__:Downloading 865 tweets from bucknerwebb\n",
      "INFO:__main__:Updated new tweets on spreadsheet for bucknerwebb\n",
      "INFO:__main__:Downloading 180 tweets from chuckwinderid\n",
      "INFO:__main__:Updated new tweets on spreadsheet for chuckwinderid\n",
      "INFO:__main__:Downloading 49 tweets from lori_denhartog\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lori_denhartog\n",
      "INFO:__main__:Downloading 30 tweets from leeheider\n",
      "INFO:__main__:Updated new tweets on spreadsheet for leeheider\n",
      "INFO:__main__:Downloading 41 tweets from vote4nye\n",
      "INFO:__main__:Updated new tweets on spreadsheet for vote4nye\n",
      "INFO:__main__:Downloading 210 tweets from senator_hill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senator_hill\n",
      "INFO:__main__:Downloading 1672 tweets from butchotter\n",
      "INFO:__main__:Updated new tweets on spreadsheet for butchotter\n",
      "INFO:__main__:Downloading 837 tweets from ltgovbradlittle\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ltgovbradlittle\n",
      "INFO:__main__:Downloading 14 tweets from denney4idaho\n",
      "INFO:__main__:Updated new tweets on spreadsheet for denney4idaho\n",
      "INFO:__main__:Downloading 210 tweets from idahocontroller\n",
      "INFO:__main__:Updated new tweets on spreadsheet for idahocontroller\n",
      "INFO:__main__:Downloading 1127 tweets from lawrencewasden\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lawrencewasden\n",
      "INFO:__main__:Downloading 173 tweets from idahosde\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Updated new tweets on spreadsheet for idahosde\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 15 tweets from omaraquinoil2\n",
      "INFO:__main__:Updated new tweets on spreadsheet for omaraquinoil2\n",
      "INFO:__main__:Downloading 41 tweets from SenatorHunter\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorHunter\n",
      "INFO:__main__:Downloading 74 tweets from LLCoolK_4\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LLCoolK_4\n",
      "INFO:__main__:Downloading 0 tweets from HeatherSteans\n",
      "INFO:__main__:Downloading 0 tweets from SenSilverstein\n",
      "INFO:__main__:Downloading 103 tweets from danielbiss\n",
      "INFO:__main__:Updated new tweets on spreadsheet for danielbiss\n",
      "INFO:__main__:Downloading 0 tweets from SenatorMulroe\n",
      "INFO:__main__:Downloading 93 tweets from SenatorSandoval\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorSandoval\n",
      "INFO:__main__:Downloading 192 tweets from KwameRaoul\n",
      "INFO:__main__:Updated new tweets on spreadsheet for KwameRaoul\n",
      "INFO:__main__:Downloading 0 tweets from Senator14\n",
      "INFO:__main__:Downloading 27 tweets from SenHarrisIL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenHarrisIL\n",
      "INFO:__main__:Downloading 13 tweets from senatorjacqui\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorjacqui\n",
      "INFO:__main__:Downloading 180 tweets from elgiesims\n",
      "INFO:__main__:Updated new tweets on spreadsheet for elgiesims\n",
      "INFO:__main__:Downloading 1 tweets from SenatorBillC\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorBillC\n",
      "INFO:__main__:Downloading 130 tweets from HastingsforIL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for HastingsforIL\n",
      "INFO:__main__:Downloading 34 tweets from ILSenMartinez\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ILSenMartinez\n",
      "INFO:__main__:Downloading 2 tweets from castroforil22\n",
      "INFO:__main__:Updated new tweets on spreadsheet for castroforil22\n",
      "INFO:__main__:Downloading 263 tweets from sentomcullerton\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sentomcullerton\n",
      "INFO:__main__:Downloading 43 tweets from chrisnybo\n",
      "INFO:__main__:Updated new tweets on spreadsheet for chrisnybo\n",
      "INFO:__main__:Downloading 0 tweets from JimOberweis\n",
      "INFO:__main__:Downloading 66 tweets from danmcconchie\n",
      "INFO:__main__:Updated new tweets on spreadsheet for danmcconchie\n",
      "INFO:__main__:Downloading 92 tweets from sentomrooney\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sentomrooney\n",
      "INFO:__main__:Downloading 136 tweets from SenatorLaura\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorLaura\n",
      "INFO:__main__:Downloading 0 tweets from morrisonfor29th\n",
      "INFO:__main__:Downloading 54 tweets from SenatorBush\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorBush\n",
      "INFO:__main__:Downloading 0 tweets from pamela_althoff\n",
      "INFO:__main__:Downloading 27 tweets from kmcconnaughay33\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kmcconnaughay33\n",
      "INFO:__main__:Downloading 0 tweets from SteveStadelman\n",
      "INFO:__main__:Downloading 14 tweets from Sen1Dave\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Sen1Dave\n",
      "INFO:__main__:Downloading 0 tweets from electneil\n",
      "INFO:__main__:Downloading 34 tweets from senatorweaver\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorweaver\n",
      "INFO:__main__:Downloading 101 tweets from SenatorRezin\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorRezin\n",
      "INFO:__main__:Downloading 114 tweets from DonHarmonIL\n",
      "INFO:__main__:Updated new tweets on spreadsheet for DonHarmonIL\n",
      "INFO:__main__:Downloading 17 tweets from ToiHutchinson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ToiHutchinson\n",
      "INFO:__main__:Downloading 0 tweets from SenJohnCurran\n",
      "INFO:__main__:Downloading 15 tweets from SenatorHolmes\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorHolmes\n",
      "INFO:__main__:Downloading 9 tweets from PatMcGuire43\n",
      "INFO:__main__:Updated new tweets on spreadsheet for PatMcGuire43\n",
      "INFO:__main__:Downloading 7 tweets from Bill_Brady\n",
      "INFO:__main__:Updated new tweets on spreadsheet for Bill_Brady\n",
      "INFO:__main__:Downloading 0 tweets from KoehlerIL\n",
      "INFO:__main__:Downloading 0 tweets from jiltracy\n",
      "INFO:__main__:Downloading 359 tweets from AndyManar\n",
      "INFO:__main__:Updated new tweets on spreadsheet for AndyManar\n",
      "INFO:__main__:Downloading 100 tweets from 49JBT\n",
      "INFO:__main__:Updated new tweets on spreadsheet for 49JBT\n",
      "INFO:__main__:Downloading 52 tweets from mccann_sam\n",
      "INFO:__main__:Updated new tweets on spreadsheet for mccann_sam\n",
      "INFO:__main__:Downloading 0 tweets from SenChapinRose\n",
      "INFO:__main__:Downloading 21 tweets from scottbennett52\n",
      "INFO:__main__:Updated new tweets on spreadsheet for scottbennett52\n",
      "INFO:__main__:Downloading 32 tweets from jasonbarickman\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jasonbarickman\n",
      "INFO:__main__:Downloading 21 tweets from kylemccarteril\n",
      "INFO:__main__:Updated new tweets on spreadsheet for kylemccarteril\n",
      "INFO:__main__:Downloading 0 tweets from senhaineil56\n",
      "INFO:__main__:Downloading 0 tweets from jamesclayborne\n",
      "INFO:__main__:Downloading 0 tweets from schimpf_4_il_ag\n",
      "INFO:__main__:Downloading 30 tweets from senatorfowler59\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorfowler59\n",
      "INFO:__main__:Downloading 51 tweets from LisaMadigan\n",
      "INFO:__main__:Updated new tweets on spreadsheet for LisaMadigan\n",
      "INFO:__main__:Downloading 277 tweets from susanamendoza10\n",
      "INFO:__main__:Updated new tweets on spreadsheet for susanamendoza10\n",
      "INFO:__main__:Downloading 707 tweets from GovRauner\n",
      "INFO:__main__:Updated new tweets on spreadsheet for GovRauner\n",
      "INFO:__main__:Downloading 68 tweets from ltsanguinetti\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ltsanguinetti\n",
      "INFO:__main__:Downloading 134 tweets from ILSecOfState\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ILSecOfState\n",
      "INFO:__main__:Downloading 292 tweets from ISBEnews\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ISBEnews\n",
      "INFO:__main__:Downloading 391 tweets from iltreasurer\n",
      "INFO:__main__:Updated new tweets on spreadsheet for iltreasurer\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n",
      "INFO:__main__:Downloading 90 tweets from SenatorMrvan\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorMrvan\n",
      "INFO:__main__:Downloading 93 tweets from SenatorRandolph\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenatorRandolph\n",
      "INFO:__main__:Downloading 1 tweets from eddiemelton4in\n",
      "INFO:__main__:Updated new tweets on spreadsheet for eddiemelton4in\n",
      "INFO:__main__:Downloading 96 tweets from senkarentallian\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senkarentallian\n",
      "INFO:__main__:Downloading 77 tweets from senatorcharb\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senatorcharb\n",
      "INFO:__main__:Downloading 86 tweets from senniezgodski\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senniezgodski\n",
      "INFO:__main__:Downloading 0 tweets from blakedoriot\n",
      "INFO:__main__:Downloading 139 tweets from lizbrownus\n",
      "INFO:__main__:Updated new tweets on spreadsheet for lizbrownus\n",
      "INFO:__main__:Downloading 0 tweets from davidlongsenate\n",
      "INFO:__main__:Downloading 189 tweets from randy_head\n",
      "INFO:__main__:Updated new tweets on spreadsheet for randy_head\n",
      "INFO:__main__:Downloading 86 tweets from repkenbuck\n",
      "INFO:__main__:Updated new tweets on spreadsheet for repkenbuck\n",
      "INFO:__main__:Downloading 78 tweets from ronalting\n",
      "INFO:__main__:Updated new tweets on spreadsheet for ronalting\n",
      "INFO:__main__:Downloading 22 tweets from votejohncrane\n",
      "INFO:__main__:Updated new tweets on spreadsheet for votejohncrane\n",
      "INFO:__main__:Downloading 104 tweets from timlanane\n",
      "INFO:__main__:Updated new tweets on spreadsheet for timlanane\n",
      "INFO:__main__:Downloading 0 tweets from candidatedoug\n",
      "INFO:__main__:Downloading 41 tweets from mikemcrider700\n",
      "INFO:__main__:Updated new tweets on spreadsheet for mikemcrider700\n",
      "INFO:__main__:Downloading 740 tweets from MikeDelph\n",
      "INFO:__main__:Updated new tweets on spreadsheet for MikeDelph\n",
      "INFO:__main__:Downloading 371 tweets from jim_merritt\n",
      "INFO:__main__:Updated new tweets on spreadsheet for jim_merritt\n",
      "INFO:__main__:Downloading 7 tweets from freemanforindy\n",
      "INFO:__main__:Updated new tweets on spreadsheet for freemanforindy\n",
      "INFO:__main__:Downloading 97 tweets from Sen_GregTaylor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Updated new tweets on spreadsheet for Sen_GregTaylor\n",
      "INFO:__main__:Downloading 104 tweets from senjeanbreaux\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senjeanbreaux\n",
      "INFO:__main__:Downloading 17 tweets from bray_rodric\n",
      "INFO:__main__:Updated new tweets on spreadsheet for bray_rodric\n",
      "INFO:__main__:Downloading 44 tweets from votejonford\n",
      "INFO:__main__:Updated new tweets on spreadsheet for votejonford\n",
      "INFO:__main__:Downloading 39 tweets from basslerinsenate\n",
      "INFO:__main__:Updated new tweets on spreadsheet for basslerinsenate\n",
      "INFO:__main__:Downloading 45 tweets from SenMarkStoops\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SenMarkStoops\n",
      "INFO:__main__:Downloading 36 tweets from sen_jeanleising\n",
      "INFO:__main__:Updated new tweets on spreadsheet for sen_jeanleising\n",
      "INFO:__main__:Downloading 0 tweets from senatorjimsmith\n",
      "INFO:__main__:Downloading 28 tweets from senrongrooms\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senrongrooms\n",
      "INFO:__main__:Downloading 68 tweets from erin_houchin\n",
      "INFO:__main__:Updated new tweets on spreadsheet for erin_houchin\n",
      "INFO:__main__:Downloading 0 tweets from messmer_m\n",
      "INFO:__main__:Downloading 23 tweets from senjimtomes\n",
      "INFO:__main__:Updated new tweets on spreadsheet for senjimtomes\n",
      "INFO:__main__:Downloading 0 tweets from senatorbecker\n",
      "INFO:__main__:Downloading 190 tweets from agcurtishill\n",
      "INFO:__main__:Updated new tweets on spreadsheet for agcurtishill\n",
      "INFO:__main__:Downloading 18 tweets from in_auditor\n",
      "INFO:__main__:Updated new tweets on spreadsheet for in_auditor\n",
      "INFO:__main__:Downloading 744 tweets from govholcomb\n",
      "INFO:__main__:Updated new tweets on spreadsheet for govholcomb\n",
      "INFO:__main__:Downloading 26 tweets from tos_mitchell\n",
      "INFO:__main__:Updated new tweets on spreadsheet for tos_mitchell\n",
      "INFO:__main__:Downloading 70 tweets from suzanne_crouch\n",
      "INFO:__main__:Updated new tweets on spreadsheet for suzanne_crouch\n",
      "INFO:__main__:Downloading 183 tweets from suptdrmccormick\n",
      "INFO:__main__:Updated new tweets on spreadsheet for suptdrmccormick\n",
      "INFO:__main__:Downloading 104 tweets from SecretaryLawson\n",
      "INFO:__main__:Updated new tweets on spreadsheet for SecretaryLawson\n",
      "INFO:__main__:Downloaded /Users/SoloMune/Dropbox/Summer_of_Tweets/State_Leg_Working_Data/Twitter_List.xlsx\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "[{u'message': u'since_id parameter is invalid.', u'code': 44}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6c8f3d7bea2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_data_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstate_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_data_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtwitter_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sheets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f02745b77640>\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(tweet_sheet, twitter_list, twitter_list_sheet)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_new_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msince_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;31m# if there are no new tweets continue to the next account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-87d97e0d1745>\u001b[0m in \u001b[0;36mget_new_tweets\u001b[0;34m(tweet_name, since_id)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthenticate_twitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msince_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msince_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SoloMune/miniconda2/envs/twitter-projects/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SoloMune/miniconda2/envs/twitter-projects/lib/python2.7/site-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: [{u'message': u'since_id parameter is invalid.', u'code': 44}]"
     ]
    }
   ],
   "source": [
    "collect_data(state_data_dir + state_tweets, state_data_dir + twitter_list, state_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
